{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "\n",
    "from src.utils.utils_fn import capture_variables, gather_variable_info, load_features_names\n",
    "from config.config import settings\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import json\n",
    "import toml\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>local_pickup</th>\n",
       "      <th>free_shipping</th>\n",
       "      <th>shipping_mode</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>buying_mode</th>\n",
       "      <th>attribute_group_id</th>\n",
       "      <th>attribute_group</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>accepts_mercadopago</th>\n",
       "      <th>currency</th>\n",
       "      <th>automatic_relist</th>\n",
       "      <th>title</th>\n",
       "      <th>stock_quantity</th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>date_difference_hr</th>\n",
       "      <th>time_difference_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mla5501620002</th>\n",
       "      <td>used</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>nuñez</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>timbre inahalambrico</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla2357269269</th>\n",
       "      <td>used</td>\n",
       "      <td>buenos aires</td>\n",
       "      <td>avellaneda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>dflt</td>\n",
       "      <td>otros</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>lote de 2 cinturones. 1 nuevo con etiqueta.mic...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.485278</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4505955642</th>\n",
       "      <td>used</td>\n",
       "      <td>buenos aires</td>\n",
       "      <td>acassuso</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>revista instituto de historia del derecho rica...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7853937105</th>\n",
       "      <td>used</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>retiro</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>free</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>susan sontag - la enfermedad y sus metaforas -...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7813601724</th>\n",
       "      <td>new</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>almagro</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>silver</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>vendas cambric marca vendsur de 10cm x 3mt en ...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              condition            state        city  local_pickup  \\\n",
       "product_id                                                           \n",
       "mla5501620002      used  capital federal       nuñez          True   \n",
       "mla2357269269      used     buenos aires  avellaneda          True   \n",
       "mla4505955642      used     buenos aires    acassuso          True   \n",
       "mla7853937105      used  capital federal      retiro          True   \n",
       "mla7813601724       new  capital federal     almagro          True   \n",
       "\n",
       "               free_shipping  shipping_mode listing_type buying_mode  \\\n",
       "product_id                                                             \n",
       "mla5501620002          False  not_specified       bronze  buy_it_now   \n",
       "mla2357269269          False  not_specified       bronze  buy_it_now   \n",
       "mla4505955642          False            me2       bronze  buy_it_now   \n",
       "mla7853937105          False  not_specified         free  buy_it_now   \n",
       "mla7813601724          False  not_specified       silver  buy_it_now   \n",
       "\n",
       "              attribute_group_id attribute_group  ...  status  \\\n",
       "product_id                                        ...           \n",
       "mla5501620002               None            None  ...  active   \n",
       "mla2357269269               dflt           otros  ...  active   \n",
       "mla4505955642               None            None  ...  active   \n",
       "mla7853937105               None            None  ...  active   \n",
       "mla7813601724               None            None  ...  active   \n",
       "\n",
       "              accepts_mercadopago  currency automatic_relist  \\\n",
       "product_id                                                     \n",
       "mla5501620002                True       ars            False   \n",
       "mla2357269269                True       ars            False   \n",
       "mla4505955642                True       ars            False   \n",
       "mla7853937105                True       ars            False   \n",
       "mla7813601724                True       ars            False   \n",
       "\n",
       "                                                           title  \\\n",
       "product_id                                                         \n",
       "mla5501620002                               timbre inahalambrico   \n",
       "mla2357269269  lote de 2 cinturones. 1 nuevo con etiqueta.mic...   \n",
       "mla4505955642  revista instituto de historia del derecho rica...   \n",
       "mla7853937105  susan sontag - la enfermedad y sus metaforas -...   \n",
       "mla7813601724  vendas cambric marca vendsur de 10cm x 3mt en ...   \n",
       "\n",
       "              stock_quantity  available_quantity  total_amount  \\\n",
       "product_id                                                       \n",
       "mla5501620002              1                   1           0.0   \n",
       "mla2357269269              8                   8           0.0   \n",
       "mla4505955642              3                   3           0.0   \n",
       "mla7853937105              1                   1           0.0   \n",
       "mla7813601724              7                   7        2010.0   \n",
       "\n",
       "               date_difference_hr  time_difference_hr  \n",
       "product_id                                             \n",
       "mla5501620002            0.000833              1440.0  \n",
       "mla2357269269          695.485278              1440.0  \n",
       "mla4505955642            0.000833              1440.0  \n",
       "mla7853937105            0.000833              1440.0  \n",
       "mla7813601724            0.000556              1440.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura del dataset\n",
    "data_path = settings.DATA_DIR / 'processed/data_processed.parquet'\n",
    "data = pd.read_parquet(path=str(data_path))\n",
    "\n",
    "# Setear los ids como índices\n",
    "data: pd.DataFrame = data.set_index('product_id')\n",
    "data.sample(5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de los conjuntos de datos\n",
    "# ===================================================================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inicializar una semilla\n",
    "SEED = 25\n",
    "\n",
    "# Separamos los features y el target\n",
    "X = data.loc[:, data.columns != 'condition'] # type: ignore\n",
    "y = data.loc[:, data.columns == 'condition'].squeeze() # type: ignore\n",
    "\n",
    "# Verificar que los índices coinciden\n",
    "assert (X.index == y.index).all(), 'Los índices de X e y no coinciden'\n",
    "\n",
    "# Dividir el conjunto original en 70% entrenamiento y 30% para pruebas y validación\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.4, \n",
    "    random_state=SEED, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Luego, dividir el 30% restante en 20% para validación y 10% para pruebas\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=1/2, \n",
    "    random_state=SEED, \n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# Categóricas\n",
    "X_train['local_pickup'] = X_train['local_pickup'].astype('category')\n",
    "X_val['local_pickup'] = X_val['local_pickup'].astype('category')\n",
    "X_test['local_pickup'] = X_test['local_pickup'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificación del target\n",
    "le = LabelEncoder()\n",
    "y_train = pd.Series(le.fit_transform(y_train), index=y_train.index)\n",
    "y_val = pd.Series(le.transform(y_val), index=y_val.index)\n",
    "y_test = pd.Series(le.transform(y_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('feature_selection', Pipeline(steps=[('drop-features',\n",
      "                 DropFeatures(features_to_drop=['attribute_group_id',\n",
      "                                                'attribute_group',\n",
      "                                                'attribute_id', 'title',\n",
      "                                                'city'])),\n",
      "                ('constant-features',\n",
      "                 DropConstantFeatures(missing_values='ignore', tol=0.95,\n",
      "                                      variables=['stock_quantity',\n",
      "                                                 'available_quantity',\n",
      "                                                 'total_amount',\n",
      "                                                 'date_difference_hr',\n",
      "                                                 'time_difference_hr', 'state',\n",
      "                                                 'local_pickup',\n",
      "                                                 'free_ship...\n",
      "                                                 'listing_type', 'buying_mode',\n",
      "                                                 'status',\n",
      "                                                 'accepts_mercadopago',\n",
      "                                                 'currency',\n",
      "                                                 'automatic_relist'])),\n",
      "                ('match-features', MatchVariables(missing_values='ignore')),\n",
      "                ('correlated-features',\n",
      "                 DropCorrelatedFeatures(variables=['stock_quantity',\n",
      "                                                   'available_quantity',\n",
      "                                                   'total_amount',\n",
      "                                                   'date_difference_hr',\n",
      "                                                   'time_difference_hr'])),\n",
      "                ('match-categories', MatchCategories(missing_values='ignore'))])), ('feature_engineering', Pipeline(steps=[('imputer',\n",
      "                 RandomSampleImputer(random_state=25, variables=['state'])),\n",
      "                ('rare_high',\n",
      "                 RareLabelEncoder(n_categories=2,\n",
      "                                  variables=['state', 'listing_type'])),\n",
      "                ('rare_low',\n",
      "                 RareLabelEncoder(n_categories=3, variables=['shipping_mode'])),\n",
      "                ('discretiser',\n",
      "                 GeometricWidthDiscretiser(bins=8, return_object=True,\n",
      "                                           variables=['available_quantity',\n",
      "                                                      'total_amount',\n",
      "                                                      'date_difference_hr',\n",
      "                                                      'time_difference_hr'])),\n",
      "                ('encoder',\n",
      "                 OrdinalEncoder(variables=['available_quantity', 'total_amount',\n",
      "                                           'date_difference_hr',\n",
      "                                           'time_difference_hr', 'state',\n",
      "                                           'local_pickup', 'shipping_mode',\n",
      "                                           'listing_type']))]))], 'transform_input': None, 'verbose': False, 'feature_selection': Pipeline(steps=[('drop-features',\n",
      "                 DropFeatures(features_to_drop=['attribute_group_id',\n",
      "                                                'attribute_group',\n",
      "                                                'attribute_id', 'title',\n",
      "                                                'city'])),\n",
      "                ('constant-features',\n",
      "                 DropConstantFeatures(missing_values='ignore', tol=0.95,\n",
      "                                      variables=['stock_quantity',\n",
      "                                                 'available_quantity',\n",
      "                                                 'total_amount',\n",
      "                                                 'date_difference_hr',\n",
      "                                                 'time_difference_hr', 'state',\n",
      "                                                 'local_pickup',\n",
      "                                                 'free_ship...\n",
      "                                                 'listing_type', 'buying_mode',\n",
      "                                                 'status',\n",
      "                                                 'accepts_mercadopago',\n",
      "                                                 'currency',\n",
      "                                                 'automatic_relist'])),\n",
      "                ('match-features', MatchVariables(missing_values='ignore')),\n",
      "                ('correlated-features',\n",
      "                 DropCorrelatedFeatures(variables=['stock_quantity',\n",
      "                                                   'available_quantity',\n",
      "                                                   'total_amount',\n",
      "                                                   'date_difference_hr',\n",
      "                                                   'time_difference_hr'])),\n",
      "                ('match-categories', MatchCategories(missing_values='ignore'))]), 'feature_engineering': Pipeline(steps=[('imputer',\n",
      "                 RandomSampleImputer(random_state=25, variables=['state'])),\n",
      "                ('rare_high',\n",
      "                 RareLabelEncoder(n_categories=2,\n",
      "                                  variables=['state', 'listing_type'])),\n",
      "                ('rare_low',\n",
      "                 RareLabelEncoder(n_categories=3, variables=['shipping_mode'])),\n",
      "                ('discretiser',\n",
      "                 GeometricWidthDiscretiser(bins=8, return_object=True,\n",
      "                                           variables=['available_quantity',\n",
      "                                                      'total_amount',\n",
      "                                                      'date_difference_hr',\n",
      "                                                      'time_difference_hr'])),\n",
      "                ('encoder',\n",
      "                 OrdinalEncoder(variables=['available_quantity', 'total_amount',\n",
      "                                           'date_difference_hr',\n",
      "                                           'time_difference_hr', 'state',\n",
      "                                           'local_pickup', 'shipping_mode',\n",
      "                                           'listing_type']))]), 'feature_selection__memory': None, 'feature_selection__steps': [('drop-features', DropFeatures(features_to_drop=['attribute_group_id', 'attribute_group',\n",
      "                               'attribute_id', 'title', 'city'])), ('constant-features', DropConstantFeatures(missing_values='ignore', tol=0.95,\n",
      "                     variables=['stock_quantity', 'available_quantity',\n",
      "                                'total_amount', 'date_difference_hr',\n",
      "                                'time_difference_hr', 'state', 'local_pickup',\n",
      "                                'free_shipping', 'shipping_mode',\n",
      "                                'listing_type', 'buying_mode', 'status',\n",
      "                                'accepts_mercadopago', 'currency',\n",
      "                                'automatic_relist'])), ('match-features', MatchVariables(missing_values='ignore')), ('correlated-features', DropCorrelatedFeatures(variables=['stock_quantity', 'available_quantity',\n",
      "                                  'total_amount', 'date_difference_hr',\n",
      "                                  'time_difference_hr'])), ('match-categories', MatchCategories(missing_values='ignore'))], 'feature_selection__transform_input': None, 'feature_selection__verbose': False, 'feature_selection__drop-features': DropFeatures(features_to_drop=['attribute_group_id', 'attribute_group',\n",
      "                               'attribute_id', 'title', 'city']), 'feature_selection__constant-features': DropConstantFeatures(missing_values='ignore', tol=0.95,\n",
      "                     variables=['stock_quantity', 'available_quantity',\n",
      "                                'total_amount', 'date_difference_hr',\n",
      "                                'time_difference_hr', 'state', 'local_pickup',\n",
      "                                'free_shipping', 'shipping_mode',\n",
      "                                'listing_type', 'buying_mode', 'status',\n",
      "                                'accepts_mercadopago', 'currency',\n",
      "                                'automatic_relist']), 'feature_selection__match-features': MatchVariables(missing_values='ignore'), 'feature_selection__correlated-features': DropCorrelatedFeatures(variables=['stock_quantity', 'available_quantity',\n",
      "                                  'total_amount', 'date_difference_hr',\n",
      "                                  'time_difference_hr']), 'feature_selection__match-categories': MatchCategories(missing_values='ignore'), 'feature_selection__drop-features__features_to_drop': ['attribute_group_id', 'attribute_group', 'attribute_id', 'title', 'city'], 'feature_selection__constant-features__confirm_variables': False, 'feature_selection__constant-features__missing_values': 'ignore', 'feature_selection__constant-features__tol': 0.95, 'feature_selection__constant-features__variables': ['stock_quantity', 'available_quantity', 'total_amount', 'date_difference_hr', 'time_difference_hr', 'state', 'local_pickup', 'free_shipping', 'shipping_mode', 'listing_type', 'buying_mode', 'status', 'accepts_mercadopago', 'currency', 'automatic_relist'], 'feature_selection__match-features__fill_value': nan, 'feature_selection__match-features__match_dtypes': False, 'feature_selection__match-features__missing_values': 'ignore', 'feature_selection__match-features__verbose': True, 'feature_selection__correlated-features__confirm_variables': False, 'feature_selection__correlated-features__method': 'pearson', 'feature_selection__correlated-features__missing_values': 'ignore', 'feature_selection__correlated-features__threshold': 0.8, 'feature_selection__correlated-features__variables': ['stock_quantity', 'available_quantity', 'total_amount', 'date_difference_hr', 'time_difference_hr'], 'feature_selection__match-categories__ignore_format': False, 'feature_selection__match-categories__missing_values': 'ignore', 'feature_selection__match-categories__variables': None, 'feature_engineering__memory': None, 'feature_engineering__steps': [('imputer', RandomSampleImputer(random_state=25, variables=['state'])), ('rare_high', RareLabelEncoder(n_categories=2, variables=['state', 'listing_type'])), ('rare_low', RareLabelEncoder(n_categories=3, variables=['shipping_mode'])), ('discretiser', GeometricWidthDiscretiser(bins=8, return_object=True,\n",
      "                          variables=['available_quantity', 'total_amount',\n",
      "                                     'date_difference_hr',\n",
      "                                     'time_difference_hr'])), ('encoder', OrdinalEncoder(variables=['available_quantity', 'total_amount',\n",
      "                          'date_difference_hr', 'time_difference_hr', 'state',\n",
      "                          'local_pickup', 'shipping_mode', 'listing_type']))], 'feature_engineering__transform_input': None, 'feature_engineering__verbose': False, 'feature_engineering__imputer': RandomSampleImputer(random_state=25, variables=['state']), 'feature_engineering__rare_high': RareLabelEncoder(n_categories=2, variables=['state', 'listing_type']), 'feature_engineering__rare_low': RareLabelEncoder(n_categories=3, variables=['shipping_mode']), 'feature_engineering__discretiser': GeometricWidthDiscretiser(bins=8, return_object=True,\n",
      "                          variables=['available_quantity', 'total_amount',\n",
      "                                     'date_difference_hr',\n",
      "                                     'time_difference_hr']), 'feature_engineering__encoder': OrdinalEncoder(variables=['available_quantity', 'total_amount',\n",
      "                          'date_difference_hr', 'time_difference_hr', 'state',\n",
      "                          'local_pickup', 'shipping_mode', 'listing_type']), 'feature_engineering__imputer__random_state': 25, 'feature_engineering__imputer__seed': 'general', 'feature_engineering__imputer__seeding_method': 'add', 'feature_engineering__imputer__variables': ['state'], 'feature_engineering__rare_high__ignore_format': False, 'feature_engineering__rare_high__max_n_categories': None, 'feature_engineering__rare_high__missing_values': 'raise', 'feature_engineering__rare_high__n_categories': 2, 'feature_engineering__rare_high__replace_with': 'Rare', 'feature_engineering__rare_high__tol': 0.05, 'feature_engineering__rare_high__variables': ['state', 'listing_type'], 'feature_engineering__rare_low__ignore_format': False, 'feature_engineering__rare_low__max_n_categories': None, 'feature_engineering__rare_low__missing_values': 'raise', 'feature_engineering__rare_low__n_categories': 3, 'feature_engineering__rare_low__replace_with': 'Rare', 'feature_engineering__rare_low__tol': 0.05, 'feature_engineering__rare_low__variables': ['shipping_mode'], 'feature_engineering__discretiser__bins': 8, 'feature_engineering__discretiser__precision': 7, 'feature_engineering__discretiser__return_boundaries': False, 'feature_engineering__discretiser__return_object': True, 'feature_engineering__discretiser__variables': ['available_quantity', 'total_amount', 'date_difference_hr', 'time_difference_hr'], 'feature_engineering__encoder__encoding_method': 'ordered', 'feature_engineering__encoder__ignore_format': False, 'feature_engineering__encoder__missing_values': 'raise', 'feature_engineering__encoder__unseen': 'ignore', 'feature_engineering__encoder__variables': ['available_quantity', 'total_amount', 'date_difference_hr', 'time_difference_hr', 'state', 'local_pickup', 'shipping_mode', 'listing_type']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Pipeline de procesamiento\n",
    "pipe_feature_selection = joblib.load(f'{settings.SRC_DIR}/pipelines/pipeline_feature_selection.pkl')\n",
    "pipe_feature_engineering = joblib.load(f'{settings.SRC_DIR}/pipelines/pipeline_feature_engineering.pkl')\n",
    "pipe = Pipeline([\n",
    "    ('feature_selection', pipe_feature_selection),\n",
    "    ('feature_engineering', pipe_feature_engineering)\n",
    "])\n",
    "\n",
    "print(pipe.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución\n",
    "pipe.fit(X_train, y_train)\n",
    "X_train = pipe.transform(X_train)\n",
    "X_val = pipe.transform(X_val)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>local_pickup</th>\n",
       "      <th>shipping_mode</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>date_difference_hr</th>\n",
       "      <th>time_difference_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mla1354899716</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla2226746858</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1838150894</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4645501325</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7355660646</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4269481325</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1905258844</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7968471061</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1578202997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla6729331561</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               state  local_pickup  shipping_mode  listing_type  \\\n",
       "product_id                                                        \n",
       "mla1354899716      2             0              1             2   \n",
       "mla2226746858      2             0              2             0   \n",
       "mla1838150894      0             1              2             2   \n",
       "mla4645501325      1             0              2             3   \n",
       "mla7355660646      1             0              1             2   \n",
       "...              ...           ...            ...           ...   \n",
       "mla4269481325      2             0              1             2   \n",
       "mla1905258844      1             0              2             3   \n",
       "mla7968471061      1             0              2             2   \n",
       "mla1578202997      1             0              1             2   \n",
       "mla6729331561      1             0              2             3   \n",
       "\n",
       "               available_quantity  total_amount  date_difference_hr  \\\n",
       "product_id                                                            \n",
       "mla1354899716                   7             7                   0   \n",
       "mla2226746858                   7             7                   7   \n",
       "mla1838150894                   4             7                   7   \n",
       "mla4645501325                   7             7                   3   \n",
       "mla7355660646                   7             5                   7   \n",
       "...                           ...           ...                 ...   \n",
       "mla4269481325                   7             7                   7   \n",
       "mla1905258844                   7             7                   2   \n",
       "mla7968471061                   7             7                   7   \n",
       "mla1578202997                   5             7                   7   \n",
       "mla6729331561                   7             7                   7   \n",
       "\n",
       "               time_difference_hr  \n",
       "product_id                         \n",
       "mla1354899716                   2  \n",
       "mla2226746858                   2  \n",
       "mla1838150894                   2  \n",
       "mla4645501325                   2  \n",
       "mla7355660646                   2  \n",
       "...                           ...  \n",
       "mla4269481325                   2  \n",
       "mla1905258844                   2  \n",
       "mla7968471061                   2  \n",
       "mla1578202997                   2  \n",
       "mla6729331561                   2  \n",
       "\n",
       "[60000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from optuna.integration.mlflow import MLflowCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función para evaluar las métricas de xgb.cv ---\n",
    "def eval_performance_metrics(cv_results: pd.DataFrame) -> tuple[int, float, float]:\n",
    "    \"\"\"\n",
    "    Retorna:\n",
    "      - best_iteration: número de iteración óptima según 'validation-auc'.\n",
    "      - best_roc_auc: mejor AUC obtenido en validación.\n",
    "      - best_logloss: log-loss en esa iteración.\n",
    "    \"\"\"\n",
    "    best_iteration = int(cv_results['validation-auc-mean'].idxmax())\n",
    "    best_roc_auc = float(cv_results.loc[best_iteration, 'validation-auc-mean'])\n",
    "    best_logloss = float(cv_results.loc[best_iteration, 'validation-logloss-mean'])\n",
    "    return best_iteration, best_roc_auc, best_logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Función para ejecutar xgb.cv usando la API nativa (con GPU)\n",
    "# ---------------------------\n",
    "def run_experiment(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    nfold: int,\n",
    "    early_stopping_rounds: int = None\n",
    ") -> pd.DataFrame:\n",
    "    # Combinar training y validación\n",
    "    X_cv = pd.concat([X_train, X_val], axis=0)\n",
    "    y_cv = pd.concat([y_train, y_val], axis=0)\n",
    "    \n",
    "    # Vector de pesos basado en la frecuencia de cada clase\n",
    "    weight_dict = y_cv.value_counts(normalize=True).to_dict()\n",
    "    sample_weight = np.array([weight_dict[val] for val in y_cv])\n",
    "    \n",
    "    dtrain_cv = xgb.DMatrix(\n",
    "        data=X_cv,\n",
    "        label=y_cv,\n",
    "        weight=sample_weight,\n",
    "        device='gpu'  # Usa 'gpu' para activar GPU (en XGBoost 2.1.4)\n",
    "    )\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params=params,\n",
    "        dtrain=dtrain_cv,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        stratified=True,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=['auc', 'logloss'],\n",
    "        seed=params.get('seed', SEED),\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de parámetros fijos para el entrenamiento\n",
    "num_boost_round = 1000\n",
    "early_stopping_rounds = 40\n",
    "default_params = toml.load(str(settings.CONFIG_DIR / 'config.toml'))['xgb-params']\n",
    "SEED = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Función objetivo para Optuna ---\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Sugerir hiperparámetros a tunear\n",
    "    params = default_params.copy()\n",
    "    params['max_depth'] = trial.suggest_int('max_depth', 3, 10)\n",
    "    params['learning_rate'] = trial.suggest_loguniform('learning_rate', 0.001, 0.3)\n",
    "    params['min_child_weight'] = trial.suggest_int('min_child_weight', 1, 10)\n",
    "    params['subsample'] = trial.suggest_uniform('subsample', 0.5, 1.0)\n",
    "    params['colsample_bytree'] = trial.suggest_uniform('colsample_bytree', 0.5, 1.0)\n",
    "    params['reg_alpha'] = trial.suggest_loguniform('reg_alpha', 1e-8, 10.0)\n",
    "    params['reg_lambda'] = trial.suggest_loguniform('reg_lambda', 1e-8, 10.0)\n",
    "    \n",
    "    # Crear DMatrix para entrenamiento y validación\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    evals = [(dtrain, 'train'), (dval, 'validation')]\n",
    "    \n",
    "    evals_result = {}\n",
    "    # Entrenar modelo con early stopping\n",
    "    booster = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    # La métrica que se optimiza es la AUC de validación\n",
    "    best_iteration, best_roc_auc, best_logloss = eval_performance_metrics(\n",
    "        pd.DataFrame({\n",
    "            'train-auc-mean': evals_result['train']['auc'],\n",
    "            'train-logloss-mean': evals_result['train']['logloss'],\n",
    "            'validation-auc-mean': evals_result['validation']['auc'],\n",
    "            'validation-logloss-mean': evals_result['validation']['logloss']\n",
    "        })\n",
    "    )\n",
    "    trial.set_user_attr('best_iteration', best_iteration)\n",
    "    trial.set_user_attr('best_logloss', best_logloss)\n",
    "    \n",
    "    return best_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 21:25:03,450] A new study created in memory with name: no-name-91557b22-741a-4c00-a857-b6432f21a11c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96866c9a55b248aca8a6aa9bac1a5f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 21:25:07,117] Trial 2 finished with value: 0.8722359947326521 and parameters: {'max_depth': 7, 'learning_rate': 0.27995200004566057, 'min_child_weight': 9, 'subsample': 0.8827227180902415, 'colsample_bytree': 0.7031529468372253, 'reg_alpha': 1.900139078139776e-05, 'reg_lambda': 4.773366139718972e-08}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:08,267] Trial 18 finished with value: 0.8719023177913665 and parameters: {'max_depth': 5, 'learning_rate': 0.12559087985032857, 'min_child_weight': 10, 'subsample': 0.7876388654694153, 'colsample_bytree': 0.9033217214187326, 'reg_alpha': 1.1697688926152928e-05, 'reg_lambda': 0.00012826071274605873}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:10,240] Trial 16 finished with value: 0.8719848231222578 and parameters: {'max_depth': 8, 'learning_rate': 0.2303741642044798, 'min_child_weight': 10, 'subsample': 0.9977916159140366, 'colsample_bytree': 0.5712814352982354, 'reg_alpha': 0.072679806887063, 'reg_lambda': 1.141893674198265e-06}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:10,568] Trial 6 finished with value: 0.8721174511456359 and parameters: {'max_depth': 9, 'learning_rate': 0.10753887699611796, 'min_child_weight': 4, 'subsample': 0.8099820735730001, 'colsample_bytree': 0.7582460805509452, 'reg_alpha': 9.117175001090211e-07, 'reg_lambda': 4.5979798856230876e-05}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:12,681] Trial 24 finished with value: 0.8718047776640732 and parameters: {'max_depth': 6, 'learning_rate': 0.0874878103486904, 'min_child_weight': 8, 'subsample': 0.7803525658450086, 'colsample_bytree': 0.9501926594937926, 'reg_alpha': 1.7082110922505051e-06, 'reg_lambda': 2.860456809085393}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:14,183] Trial 23 finished with value: 0.8718429982284384 and parameters: {'max_depth': 10, 'learning_rate': 0.05662865862137096, 'min_child_weight': 9, 'subsample': 0.7706640895337697, 'colsample_bytree': 0.8926015214136593, 'reg_alpha': 0.06420163054273668, 'reg_lambda': 2.5452423195390557e-06}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:15,193] Trial 19 finished with value: 0.8721671816260427 and parameters: {'max_depth': 10, 'learning_rate': 0.06902525675982177, 'min_child_weight': 1, 'subsample': 0.5342626053131632, 'colsample_bytree': 0.895666757061891, 'reg_alpha': 0.0012852411254591178, 'reg_lambda': 0.20112747647752352}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:16,418] Trial 25 finished with value: 0.8718995371082862 and parameters: {'max_depth': 10, 'learning_rate': 0.1357340911162732, 'min_child_weight': 7, 'subsample': 0.8006259002075067, 'colsample_bytree': 0.7019263291892297, 'reg_alpha': 1.0906030198694304e-08, 'reg_lambda': 1.042430508234297}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:18,266] Trial 8 finished with value: 0.8718016500241528 and parameters: {'max_depth': 9, 'learning_rate': 0.03929708143218579, 'min_child_weight': 9, 'subsample': 0.5688903489255999, 'colsample_bytree': 0.6385568878892285, 'reg_alpha': 0.0005896866441588018, 'reg_lambda': 1.6436234782182045e-05}. Best is trial 2 with value: 0.8722359947326521.\n",
      "[I 2025-02-10 21:25:19,256] Trial 4 finished with value: 0.8724019959813548 and parameters: {'max_depth': 9, 'learning_rate': 0.06280349727676178, 'min_child_weight': 1, 'subsample': 0.6566801982669119, 'colsample_bytree': 0.6014528208717766, 'reg_alpha': 7.867462380465138e-07, 'reg_lambda': 0.6636713270637815}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:22,780] Trial 10 finished with value: 0.8715981874934449 and parameters: {'max_depth': 6, 'learning_rate': 0.04234454380095185, 'min_child_weight': 6, 'subsample': 0.8040352804969823, 'colsample_bytree': 0.6843955573316676, 'reg_alpha': 8.869454180107331, 'reg_lambda': 1.0071780919009531e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:23,245] Trial 21 finished with value: 0.8674950708746839 and parameters: {'max_depth': 3, 'learning_rate': 0.013978449242948077, 'min_child_weight': 9, 'subsample': 0.8001986159296145, 'colsample_bytree': 0.8518473002880771, 'reg_alpha': 1.2565985106863862, 'reg_lambda': 0.0005285480653145968}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:23,606] Trial 26 finished with value: 0.8715089190183527 and parameters: {'max_depth': 4, 'learning_rate': 0.0507584216035003, 'min_child_weight': 7, 'subsample': 0.5639422697576064, 'colsample_bytree': 0.7494730737385275, 'reg_alpha': 0.004849622978793658, 'reg_lambda': 2.2678465871449796e-08}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:25,688] Trial 11 finished with value: 0.8623011068657338 and parameters: {'max_depth': 4, 'learning_rate': 0.002481552700686201, 'min_child_weight': 9, 'subsample': 0.5403280319935173, 'colsample_bytree': 0.5267076730820599, 'reg_alpha': 1.7281225808436852e-06, 'reg_lambda': 2.226051241309247e-08}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:26,728] Trial 28 finished with value: 0.872198970917967 and parameters: {'max_depth': 10, 'learning_rate': 0.033870846428044235, 'min_child_weight': 4, 'subsample': 0.7202177822161857, 'colsample_bytree': 0.8805819935906183, 'reg_alpha': 2.865557109926121, 'reg_lambda': 0.0002691334678970027}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:31,755] Trial 27 finished with value: 0.8604263834066775 and parameters: {'max_depth': 4, 'learning_rate': 0.001619917959471079, 'min_child_weight': 6, 'subsample': 0.5341644851819856, 'colsample_bytree': 0.5115178189593506, 'reg_alpha': 0.4790035375692571, 'reg_lambda': 1.0294946333042525e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:31,960] Trial 5 finished with value: 0.8708203102580585 and parameters: {'max_depth': 6, 'learning_rate': 0.006985830497233458, 'min_child_weight': 9, 'subsample': 0.7531217332097762, 'colsample_bytree': 0.680391753744484, 'reg_alpha': 0.004605474155781334, 'reg_lambda': 8.144806221461167}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:32,832] Trial 29 finished with value: 0.8706656228193574 and parameters: {'max_depth': 3, 'learning_rate': 0.04856590460864401, 'min_child_weight': 2, 'subsample': 0.9419995258143994, 'colsample_bytree': 0.5272678058119528, 'reg_alpha': 0.008445823966729679, 'reg_lambda': 0.0015152053618630531}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:34,284] Trial 30 finished with value: 0.8573402576264155 and parameters: {'max_depth': 3, 'learning_rate': 0.0036822910482978114, 'min_child_weight': 5, 'subsample': 0.6550700826115221, 'colsample_bytree': 0.7915658990424124, 'reg_alpha': 0.005523774347717582, 'reg_lambda': 0.0011396312836943672}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:34,631] Trial 13 finished with value: 0.8712531967421577 and parameters: {'max_depth': 6, 'learning_rate': 0.01000584554089996, 'min_child_weight': 2, 'subsample': 0.694359687433076, 'colsample_bytree': 0.5569612305802646, 'reg_alpha': 0.0002608463392439153, 'reg_lambda': 1.016817933463682e-08}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:35,098] Trial 39 finished with value: 0.8721325563390779 and parameters: {'max_depth': 7, 'learning_rate': 0.28642907418612523, 'min_child_weight': 1, 'subsample': 0.8987169247022996, 'colsample_bytree': 0.6051764203925891, 'reg_alpha': 3.812128976534357e-05, 'reg_lambda': 0.020886952372343212}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:36,051] Trial 41 finished with value: 0.8719214858996891 and parameters: {'max_depth': 8, 'learning_rate': 0.2743632938396329, 'min_child_weight': 4, 'subsample': 0.6693965328618992, 'colsample_bytree': 0.6114064331630992, 'reg_alpha': 4.179316430307927e-05, 'reg_lambda': 0.014993060334639555}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:36,425] Trial 12 finished with value: 0.8702859816393055 and parameters: {'max_depth': 6, 'learning_rate': 0.0033372071974723558, 'min_child_weight': 4, 'subsample': 0.8028824242749737, 'colsample_bytree': 0.9832287694563575, 'reg_alpha': 0.004886956124243432, 'reg_lambda': 3.662832999584132e-06}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:36,937] Trial 40 finished with value: 0.8721721597024433 and parameters: {'max_depth': 8, 'learning_rate': 0.2500733936059218, 'min_child_weight': 1, 'subsample': 0.9029927348949689, 'colsample_bytree': 0.5993310382493063, 'reg_alpha': 3.869493583772611e-05, 'reg_lambda': 0.03433590787325545}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:37,166] Trial 9 finished with value: 0.8720395719059453 and parameters: {'max_depth': 8, 'learning_rate': 0.020380314129573102, 'min_child_weight': 4, 'subsample': 0.6403089797760753, 'colsample_bytree': 0.5639240519279752, 'reg_alpha': 0.004622991162805634, 'reg_lambda': 1.352714724781048e-05}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:37,650] Trial 33 finished with value: 0.8594621752631056 and parameters: {'max_depth': 3, 'learning_rate': 0.004870743380682545, 'min_child_weight': 1, 'subsample': 0.630763131240291, 'colsample_bytree': 0.5331396780348208, 'reg_alpha': 1.7648105006955997e-08, 'reg_lambda': 0.011435923167365846}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:37,672] Trial 42 finished with value: 0.8719483574555328 and parameters: {'max_depth': 8, 'learning_rate': 0.29913553000433535, 'min_child_weight': 3, 'subsample': 0.8827794165048993, 'colsample_bytree': 0.608822034297809, 'reg_alpha': 4.9548727475813964e-05, 'reg_lambda': 0.021771890589046872}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:38,693] Trial 43 finished with value: 0.872096050445473 and parameters: {'max_depth': 8, 'learning_rate': 0.2460734585360788, 'min_child_weight': 3, 'subsample': 0.8746986451298127, 'colsample_bytree': 0.613106712960207, 'reg_alpha': 3.541233241336601e-08, 'reg_lambda': 0.024933621789065108}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:40,898] Trial 34 finished with value: 0.8611348089337344 and parameters: {'max_depth': 3, 'learning_rate': 0.0060382836163958365, 'min_child_weight': 1, 'subsample': 0.638580096181973, 'colsample_bytree': 0.5078646177536692, 'reg_alpha': 2.238691934486532e-08, 'reg_lambda': 0.010426945883196061}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:42,473] Trial 3 finished with value: 0.8718467342999189 and parameters: {'max_depth': 7, 'learning_rate': 0.00464968144794376, 'min_child_weight': 1, 'subsample': 0.5609463066562386, 'colsample_bytree': 0.936675893495539, 'reg_alpha': 0.010128023429447103, 'reg_lambda': 1.2000543199924867}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:44,943] Trial 7 finished with value: 0.8690646332220185 and parameters: {'max_depth': 10, 'learning_rate': 0.0017726510141442865, 'min_child_weight': 5, 'subsample': 0.7912360898979316, 'colsample_bytree': 0.728204754561008, 'reg_alpha': 0.5743388566051598, 'reg_lambda': 0.31790826085971424}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:45,798] Trial 0 finished with value: 0.8691818442936345 and parameters: {'max_depth': 7, 'learning_rate': 0.0010245711648964662, 'min_child_weight': 3, 'subsample': 0.8138439552945862, 'colsample_bytree': 0.8398566166764634, 'reg_alpha': 6.396259953792498e-08, 'reg_lambda': 2.2284784828764322e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:47,816] Trial 44 finished with value: 0.8721019839102738 and parameters: {'max_depth': 8, 'learning_rate': 0.023230060752087417, 'min_child_weight': 4, 'subsample': 0.6562706726926313, 'colsample_bytree': 0.9890315990712748, 'reg_alpha': 2.0870910245974854e-07, 'reg_lambda': 0.034672199191977844}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:48,190] Trial 20 finished with value: 0.8717436428631848 and parameters: {'max_depth': 10, 'learning_rate': 0.008516516730233806, 'min_child_weight': 9, 'subsample': 0.5826022686419499, 'colsample_bytree': 0.7220476781604079, 'reg_alpha': 0.000915457403157709, 'reg_lambda': 2.4871202827307824e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:48,223] Trial 22 finished with value: 0.8704016389476813 and parameters: {'max_depth': 8, 'learning_rate': 0.001291937265607928, 'min_child_weight': 7, 'subsample': 0.8292898100949511, 'colsample_bytree': 0.7648860915881879, 'reg_alpha': 0.20401469219947843, 'reg_lambda': 6.394463981147234e-06}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:51,176] Trial 46 finished with value: 0.8722264056501308 and parameters: {'max_depth': 8, 'learning_rate': 0.02415118708039621, 'min_child_weight': 3, 'subsample': 0.6139201999478916, 'colsample_bytree': 0.8159072624139049, 'reg_alpha': 5.767423664591675e-08, 'reg_lambda': 0.014244455010037849}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:51,428] Trial 32 finished with value: 0.8722676583155764 and parameters: {'max_depth': 8, 'learning_rate': 0.01131467499068642, 'min_child_weight': 3, 'subsample': 0.5622263964023788, 'colsample_bytree': 0.8626619525487547, 'reg_alpha': 0.00012748789519015667, 'reg_lambda': 1.2024651919260259}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:51,816] Trial 56 finished with value: 0.8722922972795798 and parameters: {'max_depth': 9, 'learning_rate': 0.17006833496700888, 'min_child_weight': 2, 'subsample': 0.718198096166976, 'colsample_bytree': 0.8164148245607311, 'reg_alpha': 1.4728868568581048e-07, 'reg_lambda': 0.17423670613264472}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:52,423] Trial 50 finished with value: 0.8721439304893995 and parameters: {'max_depth': 9, 'learning_rate': 0.027066846718374653, 'min_child_weight': 3, 'subsample': 0.7076348664529052, 'colsample_bytree': 0.8122037526751192, 'reg_alpha': 1.9291236448739406e-07, 'reg_lambda': 0.22083065587094652}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:52,817] Trial 48 finished with value: 0.872169293537243 and parameters: {'max_depth': 9, 'learning_rate': 0.02709943638367433, 'min_child_weight': 3, 'subsample': 0.7183021493141326, 'colsample_bytree': 0.8206076003405971, 'reg_alpha': 9.413106830610177e-08, 'reg_lambda': 0.20739401548298336}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:52,892] Trial 17 finished with value: 0.869828209801563 and parameters: {'max_depth': 8, 'learning_rate': 0.0023109083637571255, 'min_child_weight': 5, 'subsample': 0.8910943672749682, 'colsample_bytree': 0.6510551517652803, 'reg_alpha': 1.9854277601684607e-07, 'reg_lambda': 0.02379102178734364}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:53,118] Trial 58 finished with value: 0.8719999484291399 and parameters: {'max_depth': 9, 'learning_rate': 0.18179033467986713, 'min_child_weight': 2, 'subsample': 0.7199230405794635, 'colsample_bytree': 0.6478400816689993, 'reg_alpha': 7.489620815439257e-06, 'reg_lambda': 0.09251316243588222}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:53,528] Trial 14 finished with value: 0.8720837359918313 and parameters: {'max_depth': 10, 'learning_rate': 0.007659256316150946, 'min_child_weight': 6, 'subsample': 0.9891715185644206, 'colsample_bytree': 0.7568379896741824, 'reg_alpha': 0.7932471979120628, 'reg_lambda': 1.1541713748342641}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:53,548] Trial 57 finished with value: 0.8720061433686607 and parameters: {'max_depth': 9, 'learning_rate': 0.1676656814724377, 'min_child_weight': 2, 'subsample': 0.7098988020742154, 'colsample_bytree': 0.6588646242086059, 'reg_alpha': 5.118113185131339e-06, 'reg_lambda': 0.20451192081193018}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:54,545] Trial 45 finished with value: 0.8721667592438026 and parameters: {'max_depth': 9, 'learning_rate': 0.024315288954672425, 'min_child_weight': 3, 'subsample': 0.8613677967410989, 'colsample_bytree': 0.8117208855067201, 'reg_alpha': 3.340389675948666e-08, 'reg_lambda': 0.011192556542742819}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:55,488] Trial 51 finished with value: 0.8722050954604479 and parameters: {'max_depth': 9, 'learning_rate': 0.02245774981030459, 'min_child_weight': 5, 'subsample': 0.7128411250561626, 'colsample_bytree': 0.8117359967231956, 'reg_alpha': 4.446835720129708e-07, 'reg_lambda': 0.3677424304143051}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:56,461] Trial 47 finished with value: 0.8723171373779832 and parameters: {'max_depth': 9, 'learning_rate': 0.020265619491745806, 'min_child_weight': 3, 'subsample': 0.6137880094989778, 'colsample_bytree': 0.8015557570235774, 'reg_alpha': 5.822562607448329e-08, 'reg_lambda': 0.0034405093621915715}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:56,762] Trial 49 finished with value: 0.8721101801370749 and parameters: {'max_depth': 9, 'learning_rate': 0.024063354867628173, 'min_child_weight': 3, 'subsample': 0.7195865918915071, 'colsample_bytree': 0.8223414637865678, 'reg_alpha': 4.660493993798455e-08, 'reg_lambda': 5.004566944212135e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:56,949] Trial 64 finished with value: 0.8722039188242077 and parameters: {'max_depth': 9, 'learning_rate': 0.16643056878140167, 'min_child_weight': 2, 'subsample': 0.6113244574327793, 'colsample_bytree': 0.845809804004124, 'reg_alpha': 8.502056338412113e-06, 'reg_lambda': 3.004497767125053}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:57,332] Trial 52 finished with value: 0.8721098683787548 and parameters: {'max_depth': 9, 'learning_rate': 0.025976159106047298, 'min_child_weight': 5, 'subsample': 0.7278307087541336, 'colsample_bytree': 0.8279186070148579, 'reg_alpha': 1.0507189668770016e-07, 'reg_lambda': 2.1141490326235357}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:57,360] Trial 37 finished with value: 0.8719459237292925 and parameters: {'max_depth': 7, 'learning_rate': 0.014543397242773226, 'min_child_weight': 3, 'subsample': 0.6784986704526554, 'colsample_bytree': 0.6140191969106182, 'reg_alpha': 1.0915025995182805e-08, 'reg_lambda': 0.007560890550788776}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:57,399] Trial 61 finished with value: 0.8719639051446549 and parameters: {'max_depth': 9, 'learning_rate': 0.17827495878453223, 'min_child_weight': 2, 'subsample': 0.5043116649030818, 'colsample_bytree': 0.6666699299552314, 'reg_alpha': 6.617621433828775e-06, 'reg_lambda': 9.641649243893161}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:57,405] Trial 36 finished with value: 0.8690179700412122 and parameters: {'max_depth': 7, 'learning_rate': 0.00440804007401645, 'min_child_weight': 3, 'subsample': 0.6817882466377656, 'colsample_bytree': 0.5007041927822502, 'reg_alpha': 1.5168566059639803e-05, 'reg_lambda': 0.045536834967206265}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:57,411] Trial 62 finished with value: 0.8720118254154614 and parameters: {'max_depth': 9, 'learning_rate': 0.15629995564820118, 'min_child_weight': 2, 'subsample': 0.5906452743044395, 'colsample_bytree': 0.6471036851703853, 'reg_alpha': 7.090220326292857e-06, 'reg_lambda': 3.9978385078721947}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:25:58,774] Trial 63 finished with value: 0.8722101238204486 and parameters: {'max_depth': 7, 'learning_rate': 0.1477495706964116, 'min_child_weight': 2, 'subsample': 0.6078178790672144, 'colsample_bytree': 0.6376931399428255, 'reg_alpha': 8.20905466166844e-06, 'reg_lambda': 9.697781883643492}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:00,280] Trial 53 finished with value: 0.8721772282893241 and parameters: {'max_depth': 9, 'learning_rate': 0.020997533427756693, 'min_child_weight': 5, 'subsample': 0.7140038221303998, 'colsample_bytree': 0.8106613678908314, 'reg_alpha': 2.624087900805186e-07, 'reg_lambda': 0.18587004056893147}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:00,619] Trial 38 finished with value: 0.8719033838036866 and parameters: {'max_depth': 7, 'learning_rate': 0.012534097304135785, 'min_child_weight': 1, 'subsample': 0.9294074860206609, 'colsample_bytree': 0.6030943358630024, 'reg_alpha': 1.3034638650685726e-08, 'reg_lambda': 0.03834336421636117}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:02,267] Trial 35 finished with value: 0.8678117972144073 and parameters: {'max_depth': 8, 'learning_rate': 0.002743275960577129, 'min_child_weight': 3, 'subsample': 0.6397317106804699, 'colsample_bytree': 0.5010934199801811, 'reg_alpha': 2.894855901661969e-08, 'reg_lambda': 0.011863626301722312}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:02,288] Trial 55 finished with value: 0.8721166868349158 and parameters: {'max_depth': 9, 'learning_rate': 0.027532128413810857, 'min_child_weight': 2, 'subsample': 0.7140260427059538, 'colsample_bytree': 0.8083001083537182, 'reg_alpha': 1.1063054191256749e-07, 'reg_lambda': 0.0030028717216165446}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:04,648] Trial 54 finished with value: 0.8721428041367594 and parameters: {'max_depth': 9, 'learning_rate': 0.02479216700498277, 'min_child_weight': 2, 'subsample': 0.7146065491797498, 'colsample_bytree': 0.6455975283019053, 'reg_alpha': 2.40231287506645e-07, 'reg_lambda': 0.12227319286866357}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:04,838] Trial 59 finished with value: 0.8720358106926648 and parameters: {'max_depth': 9, 'learning_rate': 0.028894288804509984, 'min_child_weight': 2, 'subsample': 0.7225936830948447, 'colsample_bytree': 0.8169863127159565, 'reg_alpha': 2.30250401567159e-07, 'reg_lambda': 0.11348846681610385}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:04,847] Trial 60 finished with value: 0.8721584725065215 and parameters: {'max_depth': 9, 'learning_rate': 0.02849837965769611, 'min_child_weight': 2, 'subsample': 0.6058292287647463, 'colsample_bytree': 0.8249144612606388, 'reg_alpha': 1.1874014085020807e-07, 'reg_lambda': 0.30880655105726496}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:06,403] Trial 1 finished with value: 0.8706747140942387 and parameters: {'max_depth': 9, 'learning_rate': 0.0010770931028820504, 'min_child_weight': 5, 'subsample': 0.6685823861595293, 'colsample_bytree': 0.7610983871632655, 'reg_alpha': 3.321004048326646e-05, 'reg_lambda': 0.0034461123842113232}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:08,651] Trial 65 finished with value: 0.8721590356828416 and parameters: {'max_depth': 7, 'learning_rate': 0.014436228050661746, 'min_child_weight': 2, 'subsample': 0.593138872771563, 'colsample_bytree': 0.851525676273739, 'reg_alpha': 6.469800016056771e-07, 'reg_lambda': 1.1567077063831626}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:09,478] Trial 66 finished with value: 0.8720790646453906 and parameters: {'max_depth': 7, 'learning_rate': 0.01613045646787226, 'min_child_weight': 2, 'subsample': 0.6035289980795485, 'colsample_bytree': 0.8467152813104363, 'reg_alpha': 7.025204419078955e-07, 'reg_lambda': 6.12819132760349}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:10,332] Trial 73 finished with value: 0.8721202368570763 and parameters: {'max_depth': 7, 'learning_rate': 0.0164164726997293, 'min_child_weight': 2, 'subsample': 0.5927727742829639, 'colsample_bytree': 0.8715614480720438, 'reg_alpha': 0.00020418032304973178, 'reg_lambda': 5.0468392832339234e-05}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:10,530] Trial 70 finished with value: 0.8721573662673213 and parameters: {'max_depth': 7, 'learning_rate': 0.01483228594406916, 'min_child_weight': 2, 'subsample': 0.5911319860419647, 'colsample_bytree': 0.8591072385908363, 'reg_alpha': 0.0002084502280265905, 'reg_lambda': 0.0031745028003106364}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:10,968] Trial 72 finished with value: 0.872192072008046 and parameters: {'max_depth': 7, 'learning_rate': 0.012984003736681656, 'min_child_weight': 2, 'subsample': 0.5919514483348194, 'colsample_bytree': 0.7845736463228449, 'reg_alpha': 6.527027525871035e-07, 'reg_lambda': 0.0035648072426829637}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:11,037] Trial 15 finished with value: 0.8684714677628974 and parameters: {'max_depth': 10, 'learning_rate': 0.0010383441336519526, 'min_child_weight': 3, 'subsample': 0.9648134825407861, 'colsample_bytree': 0.7243707719466508, 'reg_alpha': 0.00036259725164104463, 'reg_lambda': 4.869130679665801e-07}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:11,273] Trial 67 finished with value: 0.8722255910558107 and parameters: {'max_depth': 7, 'learning_rate': 0.014679399605825103, 'min_child_weight': 2, 'subsample': 0.6095496853065797, 'colsample_bytree': 0.856365085727539, 'reg_alpha': 4.851786015519454e-07, 'reg_lambda': 6.562980939485905}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:11,444] Trial 68 finished with value: 0.8721157616166757 and parameters: {'max_depth': 7, 'learning_rate': 0.013746958819792154, 'min_child_weight': 2, 'subsample': 0.6009807154428543, 'colsample_bytree': 0.8569095440964051, 'reg_alpha': 6.051483067538168e-07, 'reg_lambda': 2.9607321107543028}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:12,069] Trial 69 finished with value: 0.8721246215869969 and parameters: {'max_depth': 7, 'learning_rate': 0.013258049970405212, 'min_child_weight': 2, 'subsample': 0.5896341315160871, 'colsample_bytree': 0.8567107427920979, 'reg_alpha': 7.754079808603616e-07, 'reg_lambda': 5.270428514326597}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:12,221] Trial 71 finished with value: 0.8720929932025926 and parameters: {'max_depth': 7, 'learning_rate': 0.014144848895125427, 'min_child_weight': 2, 'subsample': 0.6009318184558564, 'colsample_bytree': 0.8621634728694566, 'reg_alpha': 0.00015634870787241547, 'reg_lambda': 8.650131306335545}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:12,376] Trial 74 finished with value: 0.8722330330286117 and parameters: {'max_depth': 7, 'learning_rate': 0.010638744568661516, 'min_child_weight': 2, 'subsample': 0.5032528931119282, 'colsample_bytree': 0.7844123037146038, 'reg_alpha': 5.863188780261495e-07, 'reg_lambda': 0.0031380995209863635}. Best is trial 4 with value: 0.8724019959813548.\n",
      "[I 2025-02-10 21:26:13,200] Trial 31 finished with value: 0.8721842881067651 and parameters: {'max_depth': 10, 'learning_rate': 0.0025715323096006256, 'min_child_weight': 2, 'subsample': 0.5782189989413188, 'colsample_bytree': 0.8796514008922924, 'reg_alpha': 8.20054074144806e-05, 'reg_lambda': 2.3549469117215303e-05}. Best is trial 4 with value: 0.8724019959813548.\n",
      "Mejores hiperparámetros: {'max_depth': 9, 'learning_rate': 0.06280349727676178, 'min_child_weight': 1, 'subsample': 0.6566801982669119, 'colsample_bytree': 0.6014528208717766, 'reg_alpha': 7.867462380465138e-07, 'reg_lambda': 0.6636713270637815}\n",
      "Mejor AUC en validación: 0.8724019959813548\n"
     ]
    }
   ],
   "source": [
    "# Configuración de mlflow + optuna\n",
    "mlflow.set_tracking_uri(settings.MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment('xgb_hyperparam_tuning')\n",
    "\n",
    "mlflow_callback = MLflowCallback(\n",
    "    tracking_uri=settings.MLFLOW_TRACKING_URI,\n",
    "    create_experiment=False\n",
    ")\n",
    "    \n",
    "study = optuna.create_study(\n",
    "    direction='maximize'\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=75, \n",
    "    callbacks=[mlflow_callback],\n",
    "    n_jobs=-1,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(f'Mejores hiperparámetros: {best_trial.params}')\n",
    "print(f'Mejor AUC en validación: {best_trial.value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Entrenamiento final con los mejores hiperparámetros\n",
    "# ---------------------------\n",
    "# Combinar train y validación para entrenar el modelo final\n",
    "X_train_val = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_val = pd.concat([y_train, y_val], axis=0)\n",
    "dtrain_val = xgb.DMatrix(X_train_val, label=y_train_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "final_params = default_params.copy()\n",
    "final_params.update(best_trial.params)\n",
    "\n",
    "evals_result = {}\n",
    "final_model = xgb.train(\n",
    "    final_params,\n",
    "    dtrain_val,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtrain_val, 'train'), (dtest, 'test')],\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    evals_result=evals_result,\n",
    "    verbose_eval=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.8787, Train Log-loss: 0.4206\n",
      "Val AUC: 0.8757, Train Log-loss: 0.4206\n",
      "Test AUC: 0.8732, Test Log-loss: 0.4305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "# Crear DMatrix para train y test\n",
    "dtrain_eval = xgb.DMatrix(X_train, label=y_train)\n",
    "dval_eval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest_eval  = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Obtener las probabilidades predichas para cada conjunto\n",
    "train_preds = final_model.predict(dtrain_eval)  # Para objetivo binario, retorna la probabilidad de la clase 1\n",
    "val_preds  = final_model.predict(dval_eval)\n",
    "test_preds  = final_model.predict(dtest_eval)\n",
    "\n",
    "# Calcular las métricas\n",
    "train_auc = roc_auc_score(y_train, train_preds)\n",
    "train_logloss = log_loss(y_train, train_preds)\n",
    "\n",
    "val_auc = roc_auc_score(y_val, val_preds)\n",
    "val_logloss = log_loss(y_val, val_preds)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, test_preds)\n",
    "test_logloss = log_loss(y_test, test_preds)\n",
    "\n",
    "print(f'Train AUC: {train_auc:.4f}, Train Log-loss: {train_logloss:.4f}')\n",
    "print(f'Val AUC: {val_auc:.4f}, Train Log-loss: {train_logloss:.4f}')\n",
    "print(f'Test AUC: {test_auc:.4f}, Test Log-loss: {test_logloss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#da1322"
         },
         "mode": "lines+markers",
         "name": "Train AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353
         ],
         "y": [
          0.6550716157515684,
          0.678560064796037,
          0.85621518483369,
          0.8627075716719377,
          0.8672144339656458,
          0.8662570046746829,
          0.8646234041916993,
          0.8658009742324999,
          0.8640768512717866,
          0.8646691550708184,
          0.8644634684510051,
          0.8627491134676637,
          0.8645656464410026,
          0.8632486398667418,
          0.8635666473838498,
          0.8623666126607503,
          0.8622745232084967,
          0.860977270067193,
          0.8631826154297484,
          0.8644909693881665,
          0.8653489108820569,
          0.8661457268556964,
          0.867741371733546,
          0.8681981162082437,
          0.8682335896704194,
          0.8688377001479337,
          0.8692007712250106,
          0.8701654146957158,
          0.8702157643590726,
          0.8704252053065358,
          0.8704522750585695,
          0.8703560874619534,
          0.8703125704486415,
          0.8705039437335741,
          0.8709896486379499,
          0.8712654348970534,
          0.8713389180196416,
          0.8715421023829047,
          0.8716591685165284,
          0.8714684086961507,
          0.8712829098371709,
          0.8712805389475182,
          0.8714301004746076,
          0.8714039735471972,
          0.8715123103819088,
          0.871479625166419,
          0.8714868082329488,
          0.8714827097743114,
          0.8714337485773499,
          0.8715127120251983,
          0.8718999967242501,
          0.8718933944376882,
          0.8718643328115004,
          0.8719498708897218,
          0.8719734371054554,
          0.8720136542325857,
          0.8721328926341414,
          0.8721078254416076,
          0.8722360907603813,
          0.8722680396298405,
          0.8723650311415853,
          0.8724173220808413,
          0.8724152170677324,
          0.8724813166164208,
          0.8725795155722332,
          0.8726231331535049,
          0.8726242921992418,
          0.8726161201096821,
          0.8726910900667012,
          0.8728630958482225,
          0.872862538953145,
          0.8728268951539873,
          0.8728783696071195,
          0.8728320454906293,
          0.8729434333058219,
          0.8730747549477494,
          0.8731340403886105,
          0.8731566650368204,
          0.8731896447278676,
          0.8731825339445589,
          0.8731874070907617,
          0.8731838419565863,
          0.8731865346637103,
          0.8733171535870187,
          0.8733461819000697,
          0.8733613554052818,
          0.8733795236357723,
          0.8734070666857668,
          0.8734079328273208,
          0.8733993386666048,
          0.8733928429192253,
          0.8733960211810303,
          0.8733991620441254,
          0.8734611722481478,
          0.8736223676025386,
          0.8736198458609462,
          0.8736565770511695,
          0.8737145962785616,
          0.8736801753229403,
          0.8736874614716289,
          0.873861597408249,
          0.8737364355538603,
          0.8738169024927078,
          0.873837726974437,
          0.8738991639410885,
          0.8738943762776515,
          0.874033083379128,
          0.8740376365935086,
          0.8740519273005984,
          0.8740683594766826,
          0.8741064313635202,
          0.8741093717192453,
          0.8741402674536002,
          0.8741634452255891,
          0.8741741990832421,
          0.8742831745244986,
          0.8742768312004332,
          0.8742858024909985,
          0.874294187658923,
          0.874435298648914,
          0.874315415355316,
          0.8743510453263792,
          0.8744587341262998,
          0.874610958818675,
          0.874628274735706,
          0.8746210684128355,
          0.8747036353363941,
          0.874777266796723,
          0.8747896045997432,
          0.8748167372067517,
          0.8748374699202175,
          0.8748366144640093,
          0.874848780672948,
          0.8748410765386764,
          0.8748590958028764,
          0.875498823680459,
          0.8749380366229338,
          0.874944745762953,
          0.8749550055805035,
          0.8749652660266037,
          0.8749955457822047,
          0.8750353021823692,
          0.8750538305718658,
          0.8750563541991074,
          0.8750666008171132,
          0.8751283281737486,
          0.8751411744735156,
          0.8752130554227939,
          0.8752186268877677,
          0.8752847264364563,
          0.8753047532885541,
          0.8753506421343431,
          0.8759634067990745,
          0.8759559364853093,
          0.8759585587948615,
          0.8759913194363214,
          0.8760057063115227,
          0.8760181880524354,
          0.8760370439163511,
          0.8761001119696008,
          0.8761134252818312,
          0.8761880793926015,
          0.8762012644806831,
          0.8762455313538453,
          0.8762839784848829,
          0.8762809287615014,
          0.8762522423795137,
          0.8762844580683412,
          0.8763125630418113,
          0.8763401790035767,
          0.8764110813008962,
          0.8764094709564396,
          0.8764266605349711,
          0.8764671649093367,
          0.8764917663465066,
          0.8765282700017208,
          0.8765523390572535,
          0.8765424356274106,
          0.8765121156446256,
          0.8765661420097381,
          0.8765703143229711,
          0.8766056055057196,
          0.8766495662751542,
          0.8766116200982664,
          0.8766229553644371,
          0.876684181138373,
          0.8766775348533287,
          0.876720632623958,
          0.8767301966369365,
          0.8767344657468307,
          0.8767433176129438,
          0.8767507986120545,
          0.8767862381325439,
          0.8768055094678436,
          0.8768166027423611,
          0.8768231541163933,
          0.8768230843473712,
          0.876841487026918,
          0.8768470050651631,
          0.8768515381659518,
          0.8768534420431411,
          0.8768584339852464,
          0.8768874145285166,
          0.8768950218661269,
          0.876914993091572,
          0.8769198420386095,
          0.8769303576759078,
          0.8769529879810652,
          0.8769860000424246,
          0.8769905237149671,
          0.8770081482499248,
          0.8770041506735221,
          0.8770073600485397,
          0.8770096529980236,
          0.8770273253027622,
          0.8770273875291873,
          0.8770342883768799,
          0.8770375059230443,
          0.8770291245264182,
          0.877040247028499,
          0.8770512359637581,
          0.8770569167963882,
          0.8770593832256027,
          0.8770680028425836,
          0.8770672752962493,
          0.8770793993923548,
          0.8770964425187948,
          0.8770914430340925,
          0.8770903707282209,
          0.8771146497193698,
          0.8771278612065408,
          0.8771326916113608,
          0.877182479036967,
          0.877185422535441,
          0.8771816936640559,
          0.877187704799579,
          0.8772019955066688,
          0.8771992839430522,
          0.8772207514311745,
          0.8772271085833343,
          0.8772360748455017,
          0.8772473277716553,
          0.8772567755029302,
          0.8772684501859653,
          0.8772980762498276,
          0.8773065560144894,
          0.8773088565065701,
          0.8773141407243087,
          0.8773161074564728,
          0.8773311687655547,
          0.8773317570881197,
          0.8773376843122513,
          0.877349580244798,
          0.8773743752752906,
          0.8773805306629812,
          0.8773899677089103,
          0.8773909004767376,
          0.8773812302388516,
          0.8773882995378769,
          0.8773959093896863,
          0.8774113509713661,
          0.8773990313962887,
          0.8774078882907997,
          0.8774180997100196,
          0.8774325296408788,
          0.877438738141023,
          0.877436323252888,
          0.8774477056602898,
          0.8774674182375133,
          0.8774629787906372,
          0.8774693855982272,
          0.877467961933046,
          0.8774659078324668,
          0.877466610551086,
          0.877467118419283,
          0.8774650819180968,
          0.8774756019552433,
          0.8774994962739457,
          0.8775064131496569,
          0.8774917456269927,
          0.8774910121094358,
          0.8775090470873795,
          0.8775102381891536,
          0.8775294397554312,
          0.8775461315225617,
          0.877553618492895,
          0.8775556923927914,
          0.877557487530874,
          0.8776114642405565,
          0.8776113379020569,
          0.8775703577155315,
          0.8775739215926075,
          0.8775830732769507,
          0.8775785942314405,
          0.8775892355786884,
          0.8775978693380386,
          0.8776023427266012,
          0.877601342075401,
          0.8776076432866332,
          0.8776030749870586,
          0.8776112543049404,
          0.8776179043612832,
          0.8776194323657226,
          0.8776463418375704,
          0.8776309599681166,
          0.8776357526599515,
          0.8776925679002997,
          0.8776359242540329,
          0.877659871999464,
          0.8776678470386775,
          0.8776595658957363,
          0.8776629701211762,
          0.8776675893332805,
          0.8776842163597868,
          0.8776858329897408,
          0.8777358664925738,
          0.8777473434967129,
          0.8777541902891272,
          0.877751795514584,
          0.877756262617649,
          0.8777678945593013,
          0.8777798307190319,
          0.8777882162012313,
          0.8777925827363365,
          0.8777853110442921,
          0.8777828345582817,
          0.877781144388007,
          0.8777896895218427,
          0.8777888566934254,
          0.8777938700062222,
          0.8777865624868421,
          0.8777948725430716,
          0.8777972082339384,
          0.8777999449395448,
          0.877796868817074,
          0.8778075189640184,
          0.8778136774944577,
          0.8778284672700482,
          0.8778377050657069,
          0.8778416775001197,
          0.8778529354546714,
          0.8778618885172939,
          0.8778672066767189,
          0.8778710527726321,
          0.8778849336652857,
          0.8778841605490946,
          0.8778872146723243,
          0.8778948157244371,
          0.8779040648339914,
          0.8778998302943334,
          0.8779072522097678,
          0.877911513777065,
          0.8779070158750623
         ]
        },
        {
         "line": {
          "color": "#19a042"
         },
         "mode": "lines+markers",
         "name": "Test AUC",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353
         ],
         "y": [
          0.6559923630527579,
          0.6800841530890849,
          0.8554086350475393,
          0.8619856030647554,
          0.8658977514201912,
          0.8636899311080131,
          0.8623876265234954,
          0.8639949862067989,
          0.8623115060592251,
          0.863121214995649,
          0.8624510954427727,
          0.8607382542573555,
          0.8625405060634088,
          0.8610353342566346,
          0.861223226796463,
          0.8599441334725526,
          0.8593507579100115,
          0.8579105635533165,
          0.8599124442688381,
          0.8614304888717895,
          0.8621057273725207,
          0.8631426311046018,
          0.8650178756877291,
          0.8655423415632337,
          0.8653084388339435,
          0.8663864952863038,
          0.8667113221954683,
          0.8676352671410936,
          0.8678274941927598,
          0.8681285466564843,
          0.8680997538319096,
          0.8679374761450995,
          0.8678421269415395,
          0.8681408562678288,
          0.868693300361275,
          0.868967169099947,
          0.8691086692891771,
          0.8691739383885447,
          0.8692792137247822,
          0.86905873691963,
          0.8690012116117127,
          0.8690342584931491,
          0.8691662247677104,
          0.869133147715658,
          0.8689726199245783,
          0.8687703158871545,
          0.869099638218109,
          0.8690203297254104,
          0.8689760794885509,
          0.8689988884742775,
          0.8694175359424561,
          0.8693716062079703,
          0.8693235243028737,
          0.8694929121981972,
          0.8694329531272528,
          0.8694456851272219,
          0.8694893319517605,
          0.8694362014969131,
          0.8695380072123059,
          0.869482292141351,
          0.8695147959516987,
          0.8695562101506503,
          0.8695845805866005,
          0.8696898156953499,
          0.869774062112207,
          0.8697495434582381,
          0.8697781150316285,
          0.8697546523492209,
          0.8697374048137178,
          0.8697756410411132,
          0.8698149131263259,
          0.8697842396666847,
          0.8698476884722179,
          0.8698024928893892,
          0.8698917526569452,
          0.8701140748981118,
          0.870155931599432,
          0.870103816888658,
          0.8701604370780941,
          0.8701698402534267,
          0.8701655459690769,
          0.8701307592487822,
          0.870083713201503,
          0.8702893058360752,
          0.8703101637886312,
          0.8703438040255165,
          0.8703247563099229,
          0.8703110186227524,
          0.8702837544427238,
          0.8702828996086026,
          0.8702491386892532,
          0.8702420586513557,
          0.870209544784136,
          0.8702060952770354,
          0.870368775238726,
          0.8703304384426105,
          0.8703306798075389,
          0.8704385498167557,
          0.8703772481533973,
          0.870402274679403,
          0.8704254457125221,
          0.8703862440254134,
          0.8704710033427433,
          0.870507208081992,
          0.8705713508116941,
          0.8706119202333966,
          0.8708040467163428,
          0.8707939496168412,
          0.8707849688301331,
          0.8707402760909051,
          0.8707492166501252,
          0.870716370906129,
          0.8707529477496422,
          0.8707670877116931,
          0.8707117246312588,
          0.8708400000337911,
          0.8707853912187578,
          0.870784043597908,
          0.870768465503159,
          0.8707720356927238,
          0.8707235917402347,
          0.8707173263089703,
          0.8707844760434045,
          0.8709573335595727,
          0.8709696934552773,
          0.8709656103652399,
          0.8710444662986978,
          0.8710889076161255,
          0.8710411274171893,
          0.8710601851896549,
          0.8710771109052536,
          0.8710266254077458,
          0.8710393171802269,
          0.8710153868532707,
          0.8710738725924653,
          0.8716521226194982,
          0.8712241222603472,
          0.8712474240328024,
          0.8712311117863966,
          0.87123367628876,
          0.8712060601182109,
          0.8712658985066912,
          0.8712733003644932,
          0.8712728578621246,
          0.8712958277578035,
          0.8714530367811187,
          0.871331931928332,
          0.8715236561363976,
          0.8714911322123059,
          0.8715381983733291,
          0.8715904941077993,
          0.8716375300982065,
          0.8721483990827489,
          0.8721480873197165,
          0.8721498472723188,
          0.8721795452153748,
          0.8721750196229687,
          0.8721665617936053,
          0.8721738530258151,
          0.8722346166465207,
          0.8722386293384541,
          0.8722717969023547,
          0.8722918301914057,
          0.8723207336415725,
          0.8723311223903624,
          0.8723198788074513,
          0.8721916838598951,
          0.8721952641063319,
          0.8721871381537449,
          0.87221623268448,
          0.8723991671864059,
          0.8723906791864264,
          0.8724094553664756,
          0.8723938873285987,
          0.8724260290915539,
          0.8724146849399227,
          0.8724463540298932,
          0.8723836494328889,
          0.8723900757741055,
          0.8723991873001499,
          0.872388879006336,
          0.8723802703238924,
          0.8725105470439555,
          0.8724443879114145,
          0.872460302911376,
          0.8725314552808715,
          0.8725782901338385,
          0.8725986150721777,
          0.87260327140392,
          0.8725880151290756,
          0.8725892521243331,
          0.8725905192902069,
          0.8726165364181059,
          0.8726544608824688,
          0.8726619834227349,
          0.8726482055080764,
          0.8726510516028562,
          0.8726779135080043,
          0.8726494827308221,
          0.8726528014985866,
          0.8726216654228327,
          0.8726419953896081,
          0.8727102463515277,
          0.8726902432330929,
          0.8727092507211984,
          0.8726824592141544,
          0.8726841185980366,
          0.8727222643135839,
          0.8727190662282835,
          0.8727161899628877,
          0.8727163609297119,
          0.8727124488064987,
          0.8727266491097818,
          0.8727259652424849,
          0.8727233906832494,
          0.8727317077164046,
          0.8727582075741602,
          0.8727533199343616,
          0.8727542351097148,
          0.8727310841903397,
          0.8727420662945785,
          0.8727335984083431,
          0.8727163307590959,
          0.8727666553466515,
          0.8727712111096736,
          0.8727628035646704,
          0.8727376613846366,
          0.8727422875457628,
          0.8727621297542455,
          0.8728145863986679,
          0.8727652272708256,
          0.8727743186831258,
          0.8728232755360876,
          0.8728510727303329,
          0.8728678174222354,
          0.8728317937066831,
          0.8728420718298808,
          0.8728137315645468,
          0.8728536975739285,
          0.8728695270904777,
          0.872896474479038,
          0.872949368597393,
          0.8729537232229748,
          0.8729668977253126,
          0.873028978796252,
          0.8730228038768356,
          0.8730204505687845,
          0.8730102126730748,
          0.8730142454787522,
          0.8730108563128836,
          0.8729876651660204,
          0.8729745107774268,
          0.8729901793840238,
          0.872986579023843,
          0.8729805650143789,
          0.8730003770522455,
          0.8730094885782897,
          0.872979951545186,
          0.8729918488247781,
          0.8730157037251941,
          0.8730206416493528,
          0.8729784932987441,
          0.8729831898579744,
          0.8730137225214074,
          0.873010403753643,
          0.8730459950236988,
          0.8730435009194395,
          0.8730505105592329,
          0.8730551367203591,
          0.8730317645497997,
          0.8730487807772466,
          0.8730357973554771,
          0.8730468096303319,
          0.8730310203412707,
          0.8730383719147126,
          0.873035716900501,
          0.8730564843412089,
          0.8730378791279839,
          0.8730697795260107,
          0.8730086438010406,
          0.8730174133934364,
          0.8730448284265453,
          0.8730493238483353,
          0.8730603662938061,
          0.8731070502936928,
          0.8731046115022296,
          0.8731104696301775,
          0.8731150153363275,
          0.8732317655635324,
          0.873205356217625,
          0.8730721026634459,
          0.8731262388054947,
          0.8730770858435286,
          0.8731020419714302,
          0.8731095946823123,
          0.8731059540946434,
          0.8731860067958709,
          0.873137623184614,
          0.8731403083694416,
          0.8731568016395437,
          0.8731786954499171,
          0.8731884506157702,
          0.8731893356205074,
          0.8731763119712499,
          0.8731721685399804,
          0.8731795703977823,
          0.8732913625870845,
          0.8731844379238368,
          0.8731522358196495,
          0.8731097254216484,
          0.8731244687960202,
          0.8730716299904613,
          0.8730814354406744,
          0.8731096751372883,
          0.873047594066349,
          0.8731963352034288,
          0.8732071362839713,
          0.8732588084923767,
          0.8731680753930708,
          0.8731489472225011,
          0.8731111233268584,
          0.8731395541040405,
          0.8731312169571414,
          0.8731280892699451,
          0.8731427823599569,
          0.8731283809192335,
          0.8732064926441624,
          0.8732107869285122,
          0.8732140855825327,
          0.8731621720091989,
          0.8732571893359825,
          0.873290206046803,
          0.8732904876392192,
          0.8732774740468338,
          0.8732645207956804,
          0.8732482085492745,
          0.8732498779900287,
          0.8732815470799993,
          0.8732279037246792,
          0.8732140202128645,
          0.8731937807579374,
          0.8731908340944374,
          0.8731797111939905,
          0.8731691615352483,
          0.8732027816583895,
          0.873227732757855,
          0.8732208940848858,
          0.8732204515825172,
          0.8732144275161811,
          0.873186057080231,
          0.873210686359792,
          0.8732098315256709,
          0.873205406501985
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Curva de Aprendizaje / AUC"
        },
        "xaxis": {
         "title": {
          "text": "Boosting Rounds"
         }
        },
        "yaxis": {
         "title": {
          "text": "AUC"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#da1322"
         },
         "mode": "lines+markers",
         "name": "Train Log-loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353
         ],
         "y": [
          0.6834903637245298,
          0.6769954664349556,
          0.6546352899875492,
          0.6385811537388713,
          0.6206385679751635,
          0.6106599708903581,
          0.6091238779313862,
          0.5981320598643273,
          0.5942098019924015,
          0.5833734414890408,
          0.5756071332175284,
          0.5730108738481998,
          0.5608436046523974,
          0.5585599957022815,
          0.5536455528808758,
          0.548470569434017,
          0.5446270332612098,
          0.540140578277409,
          0.5311062842806801,
          0.5249992676261812,
          0.5190689162557944,
          0.5138059820476919,
          0.5072026080393233,
          0.5006555757461115,
          0.49837898545945064,
          0.4926337815951556,
          0.48871377335404975,
          0.4839553096502088,
          0.4831753332621418,
          0.4801338498908095,
          0.4780941706226207,
          0.4774776407103054,
          0.476103824096173,
          0.47230273984209636,
          0.4697853200933896,
          0.46965678462232463,
          0.46747843369673936,
          0.4672244174160529,
          0.46528024048423394,
          0.4648287644031923,
          0.4644162039003801,
          0.4624937089148443,
          0.4598335327102337,
          0.45947437331862745,
          0.4582905113884248,
          0.4574310372618958,
          0.45574045561330856,
          0.45545994889184366,
          0.4552567514848663,
          0.4543019715536153,
          0.4528296976852929,
          0.452131768684648,
          0.45191866719271057,
          0.45059869608499575,
          0.4498597312233178,
          0.44969722444287036,
          0.4485268301191274,
          0.44791969738968185,
          0.44688744227049176,
          0.446101885450352,
          0.4455360399591736,
          0.4449696647425066,
          0.44488117216285317,
          0.4439879708060063,
          0.44312669963493245,
          0.4426447415784467,
          0.44260693588189315,
          0.44220655115838164,
          0.44179703250096647,
          0.4406590750863659,
          0.4403621406270191,
          0.4402764063800103,
          0.4401836461445433,
          0.4399259703505202,
          0.4389282799718203,
          0.4380034467282938,
          0.4379757307412394,
          0.43775999106524977,
          0.4375532054324343,
          0.43751145420115206,
          0.4374461439524952,
          0.43738963854394386,
          0.4371521168231557,
          0.43637034103705663,
          0.43616764322117085,
          0.43613577831400907,
          0.4356991799918178,
          0.4355146351729112,
          0.4353624950767611,
          0.4353345963032567,
          0.43523151961406986,
          0.4350910938344663,
          0.43496298817079804,
          0.43451693682079784,
          0.43398545061676996,
          0.4339417519921873,
          0.4339012883328018,
          0.4335788390448637,
          0.4334908213583782,
          0.4333902797054063,
          0.43327966577112964,
          0.4332635219227988,
          0.4328918974054104,
          0.4328065958771913,
          0.4325292165085353,
          0.43228355511928385,
          0.43175625545905494,
          0.4317360102941282,
          0.431454346610824,
          0.431412661858619,
          0.4313211455808982,
          0.4311032839094259,
          0.43093595202388535,
          0.43073606037766876,
          0.4306558052278517,
          0.43031614448274047,
          0.4302131552805833,
          0.43017627324934,
          0.4301564818174535,
          0.43007963474883,
          0.43007272922963163,
          0.4300429857670679,
          0.4298037806439068,
          0.4294435748549935,
          0.42940002416802164,
          0.42938105797692405,
          0.42906241088713576,
          0.42874926707619015,
          0.42871003775327554,
          0.42856923347938863,
          0.428485215316822,
          0.4283889528018088,
          0.4283001113723702,
          0.4282611340796058,
          0.42809575173603226,
          0.42787875826376476,
          0.42783507876681176,
          0.42776323401534827,
          0.42771606386099664,
          0.42761886653743786,
          0.42753686225695564,
          0.42729404617810285,
          0.4272140832864628,
          0.42719972918027777,
          0.4271669448573397,
          0.4269874161062617,
          0.426945115082548,
          0.4267922350998902,
          0.42678212067676213,
          0.4266092190299285,
          0.4265542878850931,
          0.4264148636092999,
          0.42631162996884087,
          0.42626592396608465,
          0.42625989498094713,
          0.42620109526297784,
          0.4261954228903032,
          0.4261434202478846,
          0.4261159215250624,
          0.4259920122700994,
          0.4259645962992603,
          0.4258081242577115,
          0.42577965155869424,
          0.42575959614029163,
          0.4256235852452028,
          0.425585514614428,
          0.42556556704828363,
          0.42548371359854753,
          0.4254725088486095,
          0.42536635581822374,
          0.42524894593864154,
          0.42522562490438215,
          0.4252022590898865,
          0.42512777620279196,
          0.42506799262236344,
          0.42493654790318103,
          0.4248832938081985,
          0.42486608641040474,
          0.4248443525485556,
          0.4247336140141793,
          0.42473070961535775,
          0.4246875554471942,
          0.4245773698928522,
          0.42454131665221956,
          0.42449443756023303,
          0.424423465200823,
          0.42434037443673006,
          0.42426311948740186,
          0.4242497123490051,
          0.4242277416363178,
          0.4242038112318776,
          0.42418079779919826,
          0.42410544911508224,
          0.4240273231053634,
          0.4240101473475506,
          0.42398621239614914,
          0.4239750625892666,
          0.4239494651890145,
          0.4239062440264588,
          0.42389204151285215,
          0.42387220151565197,
          0.42385849904304485,
          0.423818663849342,
          0.4237979831160701,
          0.4237283979440521,
          0.42372038523956035,
          0.4237133730469901,
          0.4236429815329635,
          0.4236064161993476,
          0.4235888686073964,
          0.4235400225422332,
          0.4235063537506385,
          0.42348313894934236,
          0.4234707998702239,
          0.42345234017867567,
          0.42343957804505644,
          0.4234016169471548,
          0.4234008219237845,
          0.423360854751276,
          0.42333560634799394,
          0.4233137099257276,
          0.4233018443874162,
          0.423267630123239,
          0.4232046492286694,
          0.4231816406842645,
          0.42317512739601243,
          0.42314491431726703,
          0.423137180325608,
          0.4231184448658848,
          0.42310827168073356,
          0.42307956343737424,
          0.4230732669575347,
          0.42302193620578094,
          0.4229984556700373,
          0.42297425061584754,
          0.4229243718098047,
          0.4229014137301468,
          0.4228696066335246,
          0.42284198500688647,
          0.42281253711407696,
          0.42280402225654223,
          0.4227706435731845,
          0.42274629607394354,
          0.42272008434992375,
          0.422666805108503,
          0.42264557633729566,
          0.4226269796792234,
          0.42261785841245003,
          0.4226051976381964,
          0.42253625877898776,
          0.4225125144422541,
          0.42249464544465565,
          0.4224849587225922,
          0.42247321666005283,
          0.42245157070481293,
          0.4224383428503022,
          0.42242637114860526,
          0.42240713328455076,
          0.42239794033920514,
          0.4223589076219206,
          0.42234483726440814,
          0.4223232867535037,
          0.4223136568403544,
          0.42230657012572353,
          0.4222557942413638,
          0.42222066841340494,
          0.4222200223114127,
          0.4222109203967083,
          0.42219831814818953,
          0.42219621984706734,
          0.4221868236043927,
          0.4221844172552985,
          0.42217892327275974,
          0.42217035221166155,
          0.4221460952091149,
          0.4221436960496906,
          0.4221362180576074,
          0.42211419859303123,
          0.4221094934776569,
          0.4221025187245992,
          0.4220985899754391,
          0.42206831828184105,
          0.42205036302912446,
          0.4220218382534197,
          0.4219971801252994,
          0.4219544541190924,
          0.42194843765959034,
          0.42192843710808886,
          0.42192392664325046,
          0.4219033798831437,
          0.42189303724013105,
          0.42187170874427504,
          0.42186906016251796,
          0.421845721573513,
          0.42182594606170404,
          0.4218016626055446,
          0.4217877884967344,
          0.4217687840207025,
          0.42176391829881593,
          0.4217608050586804,
          0.42174580362804226,
          0.4217350267207592,
          0.42172074746259514,
          0.4217105808633538,
          0.4217051246433119,
          0.4217006260351103,
          0.42168214518595803,
          0.42167630216591767,
          0.421664432862591,
          0.42165976125623117,
          0.42165851974293217,
          0.4216527256890756,
          0.4216264393787178,
          0.42161555372293585,
          0.4215969653771615,
          0.42158148815155927,
          0.42156753604905933,
          0.4215620182050436,
          0.42154490542974754,
          0.4215409610550737,
          0.42153357813140735,
          0.421512556330272,
          0.4215048447232046,
          0.421502272840576,
          0.4214850264244473,
          0.42147606289904654,
          0.4214584272641312,
          0.4214463513767803,
          0.421437088124238,
          0.4214309235072223,
          0.42142018899121847,
          0.4213973842175019,
          0.42139170193613373,
          0.4213897068650445,
          0.4213879335743144,
          0.421351841050752,
          0.4213406115502937,
          0.4213279987595202,
          0.4213211076949303,
          0.42131692248082525,
          0.42130830623516186,
          0.4212974875165197,
          0.42129447116757474,
          0.4212826679883658,
          0.4212447532858834,
          0.42124181785494913,
          0.42122884612840605,
          0.4212244253076127,
          0.4212126454036077,
          0.4212109556420626,
          0.42119806112449576,
          0.42119199745517144,
          0.4211888241240194
         ]
        },
        {
         "line": {
          "color": "#19a042"
         },
         "mode": "lines+markers",
         "name": "Test Log-loss",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353
         ],
         "y": [
          0.683479992160201,
          0.6769852866113186,
          0.6547321939080953,
          0.6386824425593018,
          0.620914627867937,
          0.6112020881637931,
          0.6095853675872087,
          0.5985961910575628,
          0.5946357960477472,
          0.583810606084764,
          0.576216614075005,
          0.5736069860830904,
          0.5615493399560452,
          0.5592431594341993,
          0.5544863473959267,
          0.5494355111427606,
          0.5457536092251539,
          0.5414653009846806,
          0.5325511479750276,
          0.5264440984427929,
          0.5205677511915564,
          0.5153123067237437,
          0.5088329038511962,
          0.502352275172621,
          0.5002038453128189,
          0.4945147192094475,
          0.490617523791641,
          0.4859551289964467,
          0.48516112917773424,
          0.48208935435041783,
          0.4801306353669614,
          0.4795083690486848,
          0.4782226825866848,
          0.47450024195313456,
          0.4720026894375682,
          0.4718804314505309,
          0.4697056664830074,
          0.46946597345713525,
          0.4675120011996478,
          0.467056895278953,
          0.46665209542568775,
          0.46471578514128925,
          0.4621120258811861,
          0.46176633154619484,
          0.4607008908808231,
          0.4599719931550324,
          0.45823162216087804,
          0.45796906007779764,
          0.45777906580353156,
          0.45689745109193025,
          0.4554022319409065,
          0.4548252901885658,
          0.45463746585063636,
          0.4532799258071929,
          0.4526284509960562,
          0.4524891559328884,
          0.45134253446469086,
          0.45079646597332323,
          0.449780410961248,
          0.4490070304969326,
          0.44853360818293875,
          0.4480495549791958,
          0.4479661942312028,
          0.44703929008911364,
          0.44619042748599314,
          0.445785648810165,
          0.4457626646814402,
          0.4454191510792356,
          0.4451057528694626,
          0.44402526423083616,
          0.4437663867527619,
          0.44372858546481003,
          0.443666487140418,
          0.44348097205844245,
          0.4425260989813134,
          0.4416659483054653,
          0.4416633227153914,
          0.44149239158430137,
          0.44132173264021984,
          0.4412816665744176,
          0.4412373952968279,
          0.4412143796836492,
          0.4410037619982613,
          0.4402626672943821,
          0.44010925468688367,
          0.4401116159569705,
          0.43968482635505496,
          0.43955969017640456,
          0.4394747904259595,
          0.4394532743280521,
          0.43940221943572394,
          0.4393316265941714,
          0.43925145107558927,
          0.4388172203780035,
          0.4383042758155731,
          0.43828997956423554,
          0.4382680892851786,
          0.43795036355830963,
          0.43790411225511927,
          0.4378636834003846,
          0.4377932922904147,
          0.437768760051101,
          0.4374363574718009,
          0.43735742547953266,
          0.43710072665162153,
          0.4368386145352677,
          0.43636936990115793,
          0.4363623793840699,
          0.43608223079587916,
          0.43605421366112423,
          0.43601054229944713,
          0.43577521896713295,
          0.43560927426865675,
          0.4354077126023942,
          0.4353722046605137,
          0.4350789894460002,
          0.43503687367388627,
          0.4350070452218468,
          0.43500706706817144,
          0.4350183180935681,
          0.43502283148408166,
          0.4349938806986145,
          0.4348000227595505,
          0.43451258371676665,
          0.43448519863383844,
          0.4344866860358161,
          0.4342104431616259,
          0.4339484598468524,
          0.43394473589269617,
          0.4338595798677503,
          0.4337841683160921,
          0.4336935400937014,
          0.43363402064703405,
          0.4336428413493064,
          0.43350479808231757,
          0.43333451029384157,
          0.43331333980757625,
          0.4332513894716423,
          0.43324371822128305,
          0.43317294225502995,
          0.43314432206166675,
          0.432928370377922,
          0.4328950047767692,
          0.4328986701217451,
          0.4328868519763608,
          0.4327494740801805,
          0.432704297604569,
          0.43258850296585005,
          0.43259683201370647,
          0.4324623218402208,
          0.4324231201276154,
          0.4323173108895178,
          0.43225058190027194,
          0.4322286183977398,
          0.43222196699555204,
          0.43217068782941787,
          0.4321700632297696,
          0.43213023946223983,
          0.4321477457245943,
          0.4320681447211231,
          0.4320620059770066,
          0.43195847717150754,
          0.43197543693728513,
          0.4319700788251386,
          0.4318749343191914,
          0.4318441911993097,
          0.43181779684141075,
          0.4317711967872776,
          0.4317685204161055,
          0.43172502480791736,
          0.43164067392929284,
          0.4316459305059194,
          0.43167528033358904,
          0.4316342891453678,
          0.4316154193621041,
          0.43154588251987513,
          0.43153359610437403,
          0.4315016156871672,
          0.4315127860849097,
          0.43144835636152273,
          0.4314513321566701,
          0.431429357207306,
          0.43139258825800425,
          0.4313611649033046,
          0.43133434939575527,
          0.43128988931470086,
          0.4312367420687209,
          0.43120526686127414,
          0.4311850338917604,
          0.4311823259549787,
          0.4311713326819947,
          0.43116206871576834,
          0.431161695987613,
          0.431118234369707,
          0.43112078100217804,
          0.4311204454625309,
          0.4311144695491257,
          0.4311017899825707,
          0.4311028230681186,
          0.4310894387496399,
          0.4311009957954131,
          0.4310874380700501,
          0.4310564062834554,
          0.43105048829851,
          0.4310268102974333,
          0.43103059933588117,
          0.4310352148706017,
          0.43100712890724824,
          0.431014406802482,
          0.4310015706381957,
          0.43097985534638067,
          0.4309598914213504,
          0.43093188093337664,
          0.4309230366155869,
          0.43089890439067713,
          0.43088655077323385,
          0.4308783885629542,
          0.4308850277264581,
          0.430864294392549,
          0.4308442810438366,
          0.430826065750666,
          0.4308462057938254,
          0.43083242339294303,
          0.4308040320659478,
          0.4308075036793565,
          0.43080098527250593,
          0.4307996856008474,
          0.43080754912646807,
          0.43078951443957775,
          0.4307783027811118,
          0.43075043968440585,
          0.430763722128691,
          0.4307471761945297,
          0.43072804547813065,
          0.4307312789510965,
          0.43071796661135775,
          0.4307074130105462,
          0.43070833525900815,
          0.4306636768049626,
          0.43066773703626643,
          0.4306507364320878,
          0.4306504491442778,
          0.43063805934554655,
          0.4306293378612749,
          0.4305912111081963,
          0.430602686541772,
          0.43060428328875444,
          0.4305938963181523,
          0.430588818649323,
          0.43056477980613383,
          0.4305606157694703,
          0.43057713818952925,
          0.4305705131477367,
          0.4305663139618653,
          0.430572631484271,
          0.4305605433367913,
          0.43057146054242057,
          0.4305703041235576,
          0.43056335658309763,
          0.4305664779358223,
          0.4305916914050253,
          0.43058408229439227,
          0.4305747542046511,
          0.4305734787394624,
          0.4305628488166403,
          0.4305740394722499,
          0.43057720695971147,
          0.4305778268196005,
          0.4305807087536583,
          0.430593336247689,
          0.4305895887873625,
          0.43059634162200366,
          0.43060072152124196,
          0.4305860859540973,
          0.4305737685733544,
          0.4305829112217665,
          0.4305684746602537,
          0.43056295895183067,
          0.4305670712209925,
          0.4305850211013911,
          0.4306035673092052,
          0.4306079801489723,
          0.4305903471112244,
          0.43057874446093936,
          0.43054143795735017,
          0.43052859633189655,
          0.4305272760697373,
          0.4305429789717351,
          0.4305707030224363,
          0.43055551852437146,
          0.43055861288038233,
          0.4305449363624056,
          0.43055017253417766,
          0.4305550264110758,
          0.4305479600387448,
          0.4305316709663478,
          0.4305355592665237,
          0.43054092531143995,
          0.4305235905193832,
          0.4305214619285888,
          0.4305045774738401,
          0.43048919776036776,
          0.4304715306013407,
          0.43046868567413693,
          0.4304780664371708,
          0.4304763586842906,
          0.4304879541503345,
          0.4304829451492732,
          0.4304681259663995,
          0.4304667752635661,
          0.4304739918510705,
          0.4304621708300753,
          0.43042396149563866,
          0.4304355025191183,
          0.4304668267816899,
          0.4304567659444104,
          0.4304895214886578,
          0.43049625585633994,
          0.43052136776993805,
          0.43053066918425237,
          0.4305312497064205,
          0.43056076468244736,
          0.4305794947279876,
          0.4305825552266987,
          0.43056352007166687,
          0.43056194905608863,
          0.4305398704375386,
          0.43054301020400226,
          0.430521078541934,
          0.4305224240024335,
          0.4305217818401917,
          0.4305077101138645,
          0.43049539880431303,
          0.4304967280170012,
          0.43050388826505515,
          0.4305041759657122,
          0.43051698154210516,
          0.4305172632121124,
          0.4305280360510987,
          0.43053018169731305,
          0.4305119335678369,
          0.4305259391762632,
          0.4305152332003386,
          0.430533166074976,
          0.4305257750389583,
          0.4305187248990177,
          0.4305133618419583,
          0.4305442999435905,
          0.43054617218036056,
          0.4305499814614379,
          0.4305471649691376,
          0.43052870594158404,
          0.430534120168259
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Curva de Aprendizaje / Log-Loss"
        },
        "xaxis": {
         "title": {
          "text": "Boosting Rounds"
         }
        },
        "yaxis": {
         "title": {
          "text": "Log-loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Curvas de aprendizaje con Plotly\n",
    "# ---------------------------\n",
    "train_auc_curve = evals_result['train']['auc']\n",
    "test_auc_curve = evals_result['test']['auc']\n",
    "train_logloss_curve = evals_result['train']['logloss']\n",
    "test_logloss_curve = evals_result['test']['logloss']\n",
    "\n",
    "# Número de boosting rounds (asumiendo que todas las listas tienen la misma longitud)\n",
    "rounds = list(range(1, len(train_auc_curve) + 1))\n",
    "\n",
    "# --- Gráfico para AUC ---\n",
    "fig_auc = go.Figure()\n",
    "fig_auc.add_trace(go.Scatter(\n",
    "    x=rounds,\n",
    "    y=train_auc_curve,\n",
    "    mode='lines+markers',\n",
    "    name='Train AUC',\n",
    "    line=dict(color='#da1322')\n",
    "))\n",
    "fig_auc.add_trace(go.Scatter(\n",
    "    x=rounds,\n",
    "    y=test_auc_curve,\n",
    "    mode='lines+markers',\n",
    "    name='Test AUC',\n",
    "    line=dict(color='#19a042')\n",
    "))\n",
    "fig_auc.update_layout(\n",
    "    title='Curva de Aprendizaje / AUC',\n",
    "    xaxis_title='Boosting Rounds',\n",
    "    yaxis_title='AUC',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig_auc.show()\n",
    "\n",
    "# --- Gráfico para Log-loss ---\n",
    "fig_logloss = go.Figure()\n",
    "fig_logloss.add_trace(go.Scatter(\n",
    "    x=rounds,\n",
    "    y=train_logloss_curve,\n",
    "    mode='lines+markers',\n",
    "    name='Train Log-loss',\n",
    "    line=dict(color='#da1322')\n",
    "))\n",
    "fig_logloss.add_trace(go.Scatter(\n",
    "    x=rounds,\n",
    "    y=test_logloss_curve,\n",
    "    mode='lines+markers',\n",
    "    name='Test Log-loss',\n",
    "    line=dict(color='#19a042')\n",
    "))\n",
    "fig_logloss.update_layout(\n",
    "    title='Curva de Aprendizaje / Log-Loss',\n",
    "    xaxis_title='Boosting Rounds',\n",
    "    yaxis_title='Log-loss',\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig_logloss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run id is: 138e83c7f6c944f982d81a5467f1c42f\n",
      "Active run name is: mysterious-wasp-983\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Registrar el modelo final y la curva en MLflow\n",
    "# ---------------------------\n",
    "artifacts_dir = Path(settings.MODELS_DIR) / 'artifacts'\n",
    "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
    "final_model_file = artifacts_dir / 'final_model.json'\n",
    "final_model.save_model(str(final_model_file))\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    current_run = mlflow.active_run()\n",
    "    print(f'Active run id is: {current_run.info.run_id}')\n",
    "    print(f'Active run name is: {current_run.info.run_name}')\n",
    "    \n",
    "    mlflow.log_params(best_trial.params)\n",
    "    mlflow.log_metric('best_val_auc', best_trial.value)\n",
    "    mlflow.log_metric('test_auc', test_auc)\n",
    "    mlflow.log_artifact(str(final_model_file), artifact_path='models')\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 21:26:44 -0500] [204760] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-02-10 21:26:44 -0500] [204760] [INFO] Listening at: http://127.0.0.1:5000 (204760)\n",
      "[2025-02-10 21:26:44 -0500] [204760] [INFO] Using worker: sync\n",
      "[2025-02-10 21:26:44 -0500] [204761] [INFO] Booting worker with pid: 204761\n",
      "[2025-02-10 21:26:44 -0500] [204762] [INFO] Booting worker with pid: 204762\n",
      "[2025-02-10 21:26:44 -0500] [204763] [INFO] Booting worker with pid: 204763\n",
      "[2025-02-10 21:26:44 -0500] [204764] [INFO] Booting worker with pid: 204764\n",
      "[2025-02-10 21:29:03 -0500] [204760] [INFO] Handling signal: int\n",
      "^C\n",
      "\n",
      "Aborted!\n",
      "[2025-02-10 21:29:03 -0500] [204763] [INFO] Worker exiting (pid: 204763)\n",
      "[2025-02-10 21:29:03 -0500] [204764] [INFO] Worker exiting (pid: 204764)\n",
      "[2025-02-10 21:29:03 -0500] [204762] [INFO] Worker exiting (pid: 204762)\n",
      "[2025-02-10 21:29:03 -0500] [204761] [INFO] Worker exiting (pid: 204761)\n",
      "[2025-02-10 21:29:03 -0500] [204760] [ERROR] Worker (pid:204763) was sent SIGHUP!\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --backend-store-uri \"{settings.MLFLOW_TRACKING_URI}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-meli-u7R8qZeO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
