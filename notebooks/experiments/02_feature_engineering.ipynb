{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "\n",
    "from src.utils.utils_fn import capture_variables, gather_variable_info\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "from feature_engine.encoding import RareLabelEncoder, OrdinalEncoder\n",
    "from feature_engine.discretisation import GeometricWidthDiscretiser\n",
    "import optuna\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "import joblib\n",
    "import toml\n",
    "\n",
    "from config.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>local_pickup</th>\n",
       "      <th>free_shipping</th>\n",
       "      <th>shipping_mode</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>buying_mode</th>\n",
       "      <th>attribute_group_id</th>\n",
       "      <th>attribute_group</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>accepts_mercadopago</th>\n",
       "      <th>currency</th>\n",
       "      <th>automatic_relist</th>\n",
       "      <th>title</th>\n",
       "      <th>stock_quantity</th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>date_difference_hr</th>\n",
       "      <th>time_difference_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mla5501620002</th>\n",
       "      <td>used</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>nuñez</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>timbre inahalambrico</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla2357269269</th>\n",
       "      <td>used</td>\n",
       "      <td>buenos aires</td>\n",
       "      <td>avellaneda</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>dflt</td>\n",
       "      <td>otros</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>lote de 2 cinturones. 1 nuevo con etiqueta.mic...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>695.485278</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4505955642</th>\n",
       "      <td>used</td>\n",
       "      <td>buenos aires</td>\n",
       "      <td>acassuso</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>revista instituto de historia del derecho rica...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7853937105</th>\n",
       "      <td>used</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>retiro</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>free</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>susan sontag - la enfermedad y sus metaforas -...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7813601724</th>\n",
       "      <td>new</td>\n",
       "      <td>capital federal</td>\n",
       "      <td>almagro</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>silver</td>\n",
       "      <td>buy_it_now</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>active</td>\n",
       "      <td>True</td>\n",
       "      <td>ars</td>\n",
       "      <td>False</td>\n",
       "      <td>vendas cambric marca vendsur de 10cm x 3mt en ...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              condition            state        city  local_pickup  \\\n",
       "product_id                                                           \n",
       "mla5501620002      used  capital federal       nuñez          True   \n",
       "mla2357269269      used     buenos aires  avellaneda          True   \n",
       "mla4505955642      used     buenos aires    acassuso          True   \n",
       "mla7853937105      used  capital federal      retiro          True   \n",
       "mla7813601724       new  capital federal     almagro          True   \n",
       "\n",
       "               free_shipping  shipping_mode listing_type buying_mode  \\\n",
       "product_id                                                             \n",
       "mla5501620002          False  not_specified       bronze  buy_it_now   \n",
       "mla2357269269          False  not_specified       bronze  buy_it_now   \n",
       "mla4505955642          False            me2       bronze  buy_it_now   \n",
       "mla7853937105          False  not_specified         free  buy_it_now   \n",
       "mla7813601724          False  not_specified       silver  buy_it_now   \n",
       "\n",
       "              attribute_group_id attribute_group  ...  status  \\\n",
       "product_id                                        ...           \n",
       "mla5501620002               None            None  ...  active   \n",
       "mla2357269269               dflt           otros  ...  active   \n",
       "mla4505955642               None            None  ...  active   \n",
       "mla7853937105               None            None  ...  active   \n",
       "mla7813601724               None            None  ...  active   \n",
       "\n",
       "              accepts_mercadopago  currency automatic_relist  \\\n",
       "product_id                                                     \n",
       "mla5501620002                True       ars            False   \n",
       "mla2357269269                True       ars            False   \n",
       "mla4505955642                True       ars            False   \n",
       "mla7853937105                True       ars            False   \n",
       "mla7813601724                True       ars            False   \n",
       "\n",
       "                                                           title  \\\n",
       "product_id                                                         \n",
       "mla5501620002                               timbre inahalambrico   \n",
       "mla2357269269  lote de 2 cinturones. 1 nuevo con etiqueta.mic...   \n",
       "mla4505955642  revista instituto de historia del derecho rica...   \n",
       "mla7853937105  susan sontag - la enfermedad y sus metaforas -...   \n",
       "mla7813601724  vendas cambric marca vendsur de 10cm x 3mt en ...   \n",
       "\n",
       "              stock_quantity  available_quantity  total_amount  \\\n",
       "product_id                                                       \n",
       "mla5501620002              1                   1           0.0   \n",
       "mla2357269269              8                   8           0.0   \n",
       "mla4505955642              3                   3           0.0   \n",
       "mla7853937105              1                   1           0.0   \n",
       "mla7813601724              7                   7        2010.0   \n",
       "\n",
       "               date_difference_hr  time_difference_hr  \n",
       "product_id                                             \n",
       "mla5501620002            0.000833              1440.0  \n",
       "mla2357269269          695.485278              1440.0  \n",
       "mla4505955642            0.000833              1440.0  \n",
       "mla7853937105            0.000833              1440.0  \n",
       "mla7813601724            0.000556              1440.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir la ruta absoluta para la carpeta de pipelines\n",
    "root_path = Path.cwd().resolve().parent.parent\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "root_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lectura del dataset\n",
    "data = pd.read_parquet(\n",
    "    path=str(root_path / 'data/processed/data_processed.parquet'), \n",
    ")\n",
    "\n",
    "# Setear los ids como índices\n",
    "data: pd.DataFrame = data.set_index('product_id')\n",
    "data.sample(5, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de los conjuntos de datos\n",
    "# ===================================================================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inicializar una semilla\n",
    "SEED = 25\n",
    "\n",
    "# Separamos los features y el target\n",
    "X = data.loc[:, data.columns != 'condition'] # type: ignore\n",
    "y = data.loc[:, data.columns == 'condition'].squeeze() # type: ignore\n",
    "\n",
    "# Verificar que los índices coinciden\n",
    "assert (X.index == y.index).all(), 'Los índices de X e y no coinciden'\n",
    "\n",
    "# Dividir el conjunto original en 70% entrenamiento y 30% para pruebas y validación\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.4, \n",
    "    random_state=SEED, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Luego, dividir el 30% restante en 20% para validación y 10% para pruebas\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=1/2, \n",
    "    random_state=SEED, \n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Subconjunto   | Proporción | Descripción                                                 |\n",
    "|---------------|------------|-------------------------------------------------------------|\n",
    "| Entrenamiento | 60%        | Se usa para entrenar el modelo.                             |\n",
    "| Validación    | 20%        | Se usa para afinar hiperparámetros y evaluar durante el ajuste. |\n",
    "| Prueba        | 20%        | Se usa para evaluar el rendimiento final del modelo.        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificación del target\n",
    "le = LabelEncoder()\n",
    "y_train = pd.Series(le.fit_transform(y_train), index=y_train.index)\n",
    "y_val = pd.Series(le.transform(y_val), index=y_val.index)\n",
    "y_test = pd.Series(le.transform(y_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tTipos de variables\n",
      "Hay 5 variables continuas\n",
      "Hay 0 variables discretas\n",
      "Hay 0 variables temporales\n",
      "Hay 15 variables categóricas\n"
     ]
    }
   ],
   "source": [
    "# Función para capturar los tipos de variables\n",
    "continuous, categoricals, discretes, temporaries = capture_variables(\n",
    "    data=X_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"continuous_more_than_threshold\": [],\n",
      "    \"continuous_less_than_threshold\": [],\n",
      "    \"categoricals_more_than_threshold\": [\n",
      "        \"attribute_group_id\",\n",
      "        \"attribute_group\",\n",
      "        \"attribute_id\"\n",
      "    ],\n",
      "    \"categoricals_less_than_threshold\": [\n",
      "        \"state\",\n",
      "        \"city\"\n",
      "    ],\n",
      "    \"categoricals_high_cardinality\": [\n",
      "        \"state\",\n",
      "        \"city\",\n",
      "        \"listing_type\",\n",
      "        \"attribute_group_id\",\n",
      "        \"attribute_group\",\n",
      "        \"attribute_id\",\n",
      "        \"title\"\n",
      "    ],\n",
      "    \"categoricals_low_cardinality\": [\n",
      "        \"local_pickup\",\n",
      "        \"free_shipping\",\n",
      "        \"shipping_mode\",\n",
      "        \"buying_mode\",\n",
      "        \"status\",\n",
      "        \"accepts_mercadopago\",\n",
      "        \"currency\",\n",
      "        \"automatic_relist\"\n",
      "    ],\n",
      "    \"discretes_more_than_threshold\": [],\n",
      "    \"discretes_less_than_threshold\": [],\n",
      "    \"discretes_high_cardinality\": [],\n",
      "    \"discretes_low_cardinality\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Capturar información de las variables\n",
    "features_selection = gather_variable_info(\n",
    "    X=X_train,\n",
    "    continuous=continuous,\n",
    "    categoricals=categoricals,\n",
    "    discretes=discretes,\n",
    "    missing_threshold=0.05,       \n",
    "    cardinality_threshold=5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "from feature_engine.preprocessing import MatchVariables, MatchCategories\n",
    "\n",
    "high_cardinality_from_eda = ['title', 'city']\n",
    "categoricals_more_than_threshold = features_selection['categoricals_more_than_threshold']\n",
    "\n",
    "# Pipeline de procesadores\n",
    "pipe = Pipeline([\n",
    "    ('drop-features', DropFeatures(features_to_drop=categoricals_more_than_threshold + high_cardinality_from_eda)),\n",
    "    ('constant-features', DropConstantFeatures(variables=[var for var in continuous + categoricals if var not in categoricals_more_than_threshold + high_cardinality_from_eda], \n",
    "                                               missing_values='ignore',\n",
    "                                               tol=0.95)),\n",
    "    ('match-features', MatchVariables(missing_values='ignore')),\n",
    "    ('correlated-features', DropCorrelatedFeatures(variables=continuous,\n",
    "                                                   missing_values='ignore',\n",
    "                                                   method='pearson',\n",
    "                                                   threshold=0.8)),\n",
    "    ('match-categories', MatchCategories(missing_values='ignore')),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "X_train = pipe.transform(X_train)\n",
    "X_val = pipe.transform(X_val)\n",
    "X_test = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/lynn/Documentos/Development/Scripts_and_Notebooks/Proyectos Profesionales/Pruebas técnicas/MELI/src/pipelines/pipeline_feature_selection.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportar la pipeline de feature selection\n",
    "path = Path(settings.SRC_DIR) / 'pipelines'\n",
    "joblib.dump(pipe, str(path / 'pipeline_feature_selection.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "# Ruta al archivo de configuración usando pathlib\n",
    "config_file_path = Path(settings.CONFIG_DIR) / 'config.toml'\n",
    "\n",
    "# Filtramos el diccionario para excluir las listas vacías\n",
    "features_selection = {'high_cardinality_from_eda': high_cardinality_from_eda} | {key: value for key, value in features_selection.items() if value}\n",
    "\n",
    "# Cargar el archivo de configuración existente, o inicializar un diccionario vacío si no existe\n",
    "if config_file_path.exists():\n",
    "    with config_file_path.open('r') as file:\n",
    "        config = toml.load(file)\n",
    "else:\n",
    "    config = {}\n",
    "    \n",
    "# Actualizamos (o agregamos) la sección 'pipeline-feature-selection'\n",
    "config['pipeline-feature-selection'] = features_selection\n",
    "\n",
    "# Escribimos los cambios en el archivo de configuración\n",
    "with config_file_path.open('w') as file:\n",
    "    toml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['local_pickup'] = X_train['local_pickup'].astype('category')\n",
    "X_val['local_pickup'] = X_val['local_pickup'].astype('category')\n",
    "X_test['local_pickup'] = X_test['local_pickup'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tTipos de variables\n",
      "Hay 4 variables continuas\n",
      "Hay 0 variables discretas\n",
      "Hay 0 variables temporales\n",
      "Hay 4 variables categóricas\n"
     ]
    }
   ],
   "source": [
    "# Función para capturar los tipos de variables\n",
    "continuous, categoricals, discretes, temporaries = capture_variables(\n",
    "    data=X_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"continuous_more_than_threshold\": [],\n",
      "    \"continuous_less_than_threshold\": [],\n",
      "    \"categoricals_more_than_threshold\": [],\n",
      "    \"categoricals_less_than_threshold\": [\n",
      "        \"state\"\n",
      "    ],\n",
      "    \"categoricals_high_cardinality\": [\n",
      "        \"state\",\n",
      "        \"listing_type\"\n",
      "    ],\n",
      "    \"categoricals_low_cardinality\": [\n",
      "        \"local_pickup\",\n",
      "        \"shipping_mode\"\n",
      "    ],\n",
      "    \"discretes_more_than_threshold\": [],\n",
      "    \"discretes_less_than_threshold\": [],\n",
      "    \"discretes_high_cardinality\": [],\n",
      "    \"discretes_low_cardinality\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Capturar información de las variables\n",
    "features_engineering = gather_variable_info(\n",
    "    X=X_train,\n",
    "    continuous=continuous,\n",
    "    categoricals=categoricals,\n",
    "    discretes=discretes,\n",
    "    missing_threshold=0.05,       \n",
    "    cardinality_threshold=5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "# Ruta al archivo de configuración usando pathlib\n",
    "config_file_path = Path(settings.CONFIG_DIR) / 'config.toml'\n",
    "\n",
    "# Filtramos el diccionario para excluir las listas vacías\n",
    "features_engineering = {key: value for key, value in features_engineering.items() if value}\n",
    "\n",
    "# Cargar el archivo de configuración existente, o inicializar un diccionario vacío si no existe\n",
    "if config_file_path.exists():\n",
    "    with config_file_path.open('r') as file:\n",
    "        config = toml.load(file)\n",
    "else:\n",
    "    config = {}\n",
    "    \n",
    "# Actualizamos (o agregamos) la sección 'pipeline-feature-selection'\n",
    "config['pipeline-feature-engineering'] = features_engineering\n",
    "\n",
    "# Escribimos los cambios en el archivo de configuración\n",
    "with config_file_path.open('w') as file:\n",
    "    toml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>local_pickup</th>\n",
       "      <th>shipping_mode</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>available_quantity</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>date_difference_hr</th>\n",
       "      <th>time_difference_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mla1354899716</th>\n",
       "      <td>buenos aires</td>\n",
       "      <td>True</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>720.154444</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla2226746858</th>\n",
       "      <td>buenos aires</td>\n",
       "      <td>True</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>gold</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>1440.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1838150894</th>\n",
       "      <td>córdoba</td>\n",
       "      <td>False</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4645501325</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>free</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.331389</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7355660646</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>1</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla4269481325</th>\n",
       "      <td>buenos aires</td>\n",
       "      <td>True</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018611</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1905258844</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>free</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.771389</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla7968471061</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>bronze</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla1578202997</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>me2</td>\n",
       "      <td>bronze</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>1440.006944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mla6729331561</th>\n",
       "      <td>capital federal</td>\n",
       "      <td>True</td>\n",
       "      <td>not_specified</td>\n",
       "      <td>free</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         state local_pickup  shipping_mode listing_type  \\\n",
       "product_id                                                                \n",
       "mla1354899716     buenos aires         True            me2       bronze   \n",
       "mla2226746858     buenos aires         True  not_specified         gold   \n",
       "mla1838150894          córdoba        False  not_specified       bronze   \n",
       "mla4645501325  capital federal         True  not_specified         free   \n",
       "mla7355660646  capital federal         True            me2       bronze   \n",
       "...                        ...          ...            ...          ...   \n",
       "mla4269481325     buenos aires         True            me2       bronze   \n",
       "mla1905258844  capital federal         True  not_specified         free   \n",
       "mla7968471061  capital federal         True  not_specified       bronze   \n",
       "mla1578202997  capital federal         True            me2       bronze   \n",
       "mla6729331561  capital federal         True  not_specified         free   \n",
       "\n",
       "               available_quantity  total_amount  date_difference_hr  \\\n",
       "product_id                                                            \n",
       "mla1354899716                   4           0.0          720.154444   \n",
       "mla2226746858                   6           0.0            0.008611   \n",
       "mla1838150894                  60           0.0            0.001111   \n",
       "mla4645501325                   6           0.0           84.331389   \n",
       "mla7355660646                   1        1350.0            0.000278   \n",
       "...                           ...           ...                 ...   \n",
       "mla4269481325                   5           0.0            0.018611   \n",
       "mla1905258844                   3           0.0            3.771389   \n",
       "mla7968471061                   2           0.0            0.000000   \n",
       "mla1578202997                  20           0.0            0.008889   \n",
       "mla6729331561                   2           0.0            0.000556   \n",
       "\n",
       "               time_difference_hr  \n",
       "product_id                         \n",
       "mla1354899716         1440.000000  \n",
       "mla2226746858         1440.006944  \n",
       "mla1838150894         1440.000000  \n",
       "mla4645501325         1440.000000  \n",
       "mla7355660646         1440.000000  \n",
       "...                           ...  \n",
       "mla4269481325         1440.000000  \n",
       "mla1905258844         1440.000000  \n",
       "mla7968471061         1440.000000  \n",
       "mla1578202997         1440.006944  \n",
       "mla6729331561         1440.000000  \n",
       "\n",
       "[60000 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Funciones necesarias\n",
    "# -----------------------------\n",
    "\n",
    "def eval_performance_metrics(cv_results: pd.DataFrame) -> tuple[int, float, float]:\n",
    "    \"\"\"\n",
    "    Evalúa los resultados de xgb.cv y retorna:\n",
    "      - best_iteration: la iteración óptima (según test-auc-mean).\n",
    "      - best_roc_auc: el valor de test-auc-mean en esa iteración.\n",
    "      - best_logloss: el valor de test-logloss-mean en esa iteración.\n",
    "    \"\"\"\n",
    "    best_iteration: int = int(cv_results['test-auc-mean'].idxmax())\n",
    "    best_roc_auc: float = float(cv_results.loc[best_iteration, 'test-auc-mean'])\n",
    "    best_logloss: float = float(cv_results.loc[best_iteration, 'test-logloss-mean'])\n",
    "    return best_iteration, best_roc_auc, best_logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.Series,\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    nfold: int,\n",
    "    early_stopping_rounds: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ejecuta la validación cruzada usando la API nativa de XGBoost (xgb.cv) sobre\n",
    "    la unión de X_train y X_val. Se utiliza un vector de pesos basado en la frecuencia\n",
    "    de las clases. Se configura para usar GPU mediante 'device': 'gpu'.\n",
    "    \"\"\"\n",
    "    X_cv: pd.DataFrame = pd.concat([X_train, X_val], axis=0)\n",
    "    y_cv: pd.Series = pd.concat([y_train, y_val], axis=0)\n",
    "    weight_dict = y_cv.value_counts(normalize=True).to_dict()\n",
    "    sample_weight: np.ndarray = np.array([weight_dict[val] for val in y_cv])\n",
    "    \n",
    "    dtrain_cv: xgb.DMatrix = xgb.DMatrix(\n",
    "        data=X_cv,\n",
    "        label=y_cv,\n",
    "        weight=sample_weight\n",
    "    )\n",
    "    \n",
    "    cv_results: pd.DataFrame = xgb.cv( # type: ignore\n",
    "        params=params,\n",
    "        dtrain=dtrain_cv,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        stratified=True,\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        metrics=['auc', 'logloss'],\n",
    "        seed=params.get('seed', SEED),\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(\n",
    "    n_cat_high: int,\n",
    "    n_cat_low: int, \n",
    "    bins: int\n",
    "    ) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Instancia primero los transformadores y luego construye la pipeline de feature engineering:\n",
    "      1. Imputación con RandomSampleImputer sobre info['categoricals_less_than_threshold'].\n",
    "      2. RareLabelEncoder para variables de alta cardinalidad (n_categories = n_cat_high).\n",
    "      3. RareLabelEncoder para variables de baja cardinalidad (n_categories = n_cat_low).\n",
    "      4. Discretización con GeometricWidthDiscretiser sobre variables continuas (bins).\n",
    "      5. Codificación con OrdinalEncoder sobre continuous + categoricals.\n",
    "    \"\"\"\n",
    "    imputer = RandomSampleImputer(\n",
    "        variables=features_engineering['categoricals_less_than_threshold'],\n",
    "        random_state=SEED\n",
    "    )\n",
    "    rare_high = RareLabelEncoder(\n",
    "        tol=0.05,\n",
    "        n_categories=n_cat_high,\n",
    "        variables=features_engineering['categoricals_high_cardinality']\n",
    "    )\n",
    "    # Aquí usamos una variable fija para baja cardinalidad, por ejemplo 'shipping_mode'\n",
    "    rare_low = RareLabelEncoder(\n",
    "        tol=0.05,\n",
    "        n_categories=n_cat_low,\n",
    "        variables=['shipping_mode']\n",
    "    )\n",
    "    discretiser = GeometricWidthDiscretiser(\n",
    "        variables=continuous,\n",
    "        bins=bins,\n",
    "        return_object=True\n",
    "    )\n",
    "    encoder = OrdinalEncoder(\n",
    "        variables=continuous + categoricals,\n",
    "        encoding_method='ordered'\n",
    "    )\n",
    "    pipe = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('rare_high', rare_high),\n",
    "        ('rare_low', rare_low),\n",
    "        ('discretiser', discretiser),\n",
    "        ('encoder', encoder)\n",
    "    ])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_experiment(\n",
    "    pipeline_params: tuple[int, int, int],\n",
    "    params: dict,\n",
    "    num_boost_round: int,\n",
    "    nfold: int,\n",
    "    early_stopping_rounds: int\n",
    ") -> tuple[float, tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Construye la pipeline de feature engineering con la configuración (n_cat_high, n_cat_low, bins),\n",
    "    la ajusta sobre X_train y transforma X_train y X_val, luego evalúa mediante run_experiment.\n",
    "    Retorna (best_roc_auc, pipeline_params).\n",
    "    \"\"\"\n",
    "    n_cat_high, n_cat_low, bins = pipeline_params\n",
    "    pipe = build_pipeline(n_cat_high, n_cat_low, bins)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    X_train_transformed: pd.DataFrame = pipe.transform(X_train)\n",
    "    X_val_transformed: pd.DataFrame = pipe.transform(X_val)\n",
    "    \n",
    "    cv_results: pd.DataFrame = run_experiment(\n",
    "        X_train=X_train_transformed,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val_transformed,\n",
    "        y_val=y_val,\n",
    "        params=params,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    best_iteration, best_roc_auc, best_logloss = eval_performance_metrics(cv_results)\n",
    "    return best_iteration, best_roc_auc, best_logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Función objetivo para Optuna (integrada con MLflow a través de callback)\n",
    "# -----------------------------\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Sugerir hiperparámetros para la parte de feature engineering\n",
    "    n_cat_high = trial.suggest_int('n_cat_high', 2, 5)\n",
    "    n_cat_low  = trial.suggest_int('n_cat_low', 2, 5)\n",
    "    bins       = trial.suggest_int('bins', 5, 10)\n",
    "    \n",
    "    best_iteration, best_roc_auc, best_logloss = run_pipeline_experiment( # type: ignore\n",
    "        pipeline_params=(n_cat_high, n_cat_low, bins),\n",
    "        params=params,\n",
    "        num_boost_round=num_boost_round,\n",
    "        nfold=nfold,\n",
    "        early_stopping_rounds=early_stopping_rounds\n",
    "    )\n",
    "    \n",
    "    # Puedes almacenar información adicional en el trial si lo deseas\n",
    "    trial.set_user_attr('best_iteration', best_iteration)\n",
    "    trial.set_user_attr('best_logloss', best_logloss)\n",
    "    \n",
    "    # Optimizamos para maximizar el ROC-AUC\n",
    "    return best_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/10 21:56:50 INFO mlflow.tracking.fluent: Experiment with name 'feature_engineering_experiment' does not exist. Creating a new experiment.\n",
      "[I 2025-02-10 21:56:50,798] A new study created in memory with name: no-name-1da3b0d1-520c-4be0-9417-f198500b9ef9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cd628c730c43d5adfd4a463a6e7b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 21:57:47,896] Trial 8 finished with value: 0.8605756741345433 and parameters: {'n_cat_high': 3, 'n_cat_low': 3, 'bins': 5}. Best is trial 8 with value: 0.8605756741345433.\n",
      "[I 2025-02-10 21:57:52,639] Trial 16 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 3, 'n_cat_low': 4, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:52,755] Trial 6 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 3, 'n_cat_low': 5, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:52,772] Trial 1 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 4, 'n_cat_low': 4, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:52,955] Trial 20 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 5, 'n_cat_low': 5, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:53,102] Trial 21 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 5, 'n_cat_low': 5, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:53,573] Trial 13 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 5, 'n_cat_low': 4, 'bins': 9}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:56,347] Trial 0 finished with value: 0.8605345641319613 and parameters: {'n_cat_high': 5, 'n_cat_low': 5, 'bins': 5}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:56,511] Trial 11 finished with value: 0.8605345641319613 and parameters: {'n_cat_high': 3, 'n_cat_low': 4, 'bins': 5}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:56,589] Trial 7 finished with value: 0.8605345641319613 and parameters: {'n_cat_high': 3, 'n_cat_low': 5, 'bins': 5}. Best is trial 16 with value: 0.8735026345906084.\n",
      "[I 2025-02-10 21:57:57,765] Trial 18 finished with value: 0.8743741851895106 and parameters: {'n_cat_high': 4, 'n_cat_low': 5, 'bins': 8}. Best is trial 18 with value: 0.8743741851895106.\n",
      "[I 2025-02-10 21:57:57,779] Trial 10 finished with value: 0.8729469006584543 and parameters: {'n_cat_high': 5, 'n_cat_low': 2, 'bins': 10}. Best is trial 18 with value: 0.8743741851895106.\n",
      "[I 2025-02-10 21:57:57,838] Trial 22 finished with value: 0.8743741851895106 and parameters: {'n_cat_high': 3, 'n_cat_low': 5, 'bins': 8}. Best is trial 18 with value: 0.8743741851895106.\n",
      "[I 2025-02-10 21:57:59,158] Trial 14 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 4, 'n_cat_low': 3, 'bins': 7}. Best is trial 18 with value: 0.8743741851895106.\n",
      "[I 2025-02-10 21:57:59,631] Trial 9 finished with value: 0.8741546500494752 and parameters: {'n_cat_high': 5, 'n_cat_low': 5, 'bins': 7}. Best is trial 18 with value: 0.8743741851895106.\n",
      "[I 2025-02-10 21:58:00,559] Trial 17 finished with value: 0.8744944159562872 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 8}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:00,665] Trial 23 finished with value: 0.8744944159562872 and parameters: {'n_cat_high': 5, 'n_cat_low': 3, 'bins': 8}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:00,877] Trial 3 finished with value: 0.8744944159562872 and parameters: {'n_cat_high': 3, 'n_cat_low': 3, 'bins': 8}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:00,942] Trial 15 finished with value: 0.8744944159562872 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 8}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:02,026] Trial 5 finished with value: 0.864386187401079 and parameters: {'n_cat_high': 3, 'n_cat_low': 4, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:03,907] Trial 4 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 5, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:04,340] Trial 2 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 5, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:04,815] Trial 19 finished with value: 0.8738107650190585 and parameters: {'n_cat_high': 3, 'n_cat_low': 2, 'bins': 9}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:04,902] Trial 12 finished with value: 0.8738107650190585 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 9}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:44,079] Trial 27 finished with value: 0.8605756741345433 and parameters: {'n_cat_high': 5, 'n_cat_low': 2, 'bins': 5}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:50,383] Trial 24 finished with value: 0.8729469006584543 and parameters: {'n_cat_high': 5, 'n_cat_low': 3, 'bins': 10}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:53,656] Trial 32 finished with value: 0.8735026345906084 and parameters: {'n_cat_high': 5, 'n_cat_low': 4, 'bins': 9}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:55,817] Trial 29 finished with value: 0.8729469006584543 and parameters: {'n_cat_high': 3, 'n_cat_low': 3, 'bins': 10}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:58,574] Trial 25 finished with value: 0.864386187401079 and parameters: {'n_cat_high': 5, 'n_cat_low': 4, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:58:59,516] Trial 30 finished with value: 0.864386187401079 and parameters: {'n_cat_high': 5, 'n_cat_low': 4, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,109] Trial 33 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,232] Trial 28 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 4, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,332] Trial 35 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 4, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,630] Trial 36 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,662] Trial 26 finished with value: 0.8738107650190585 and parameters: {'n_cat_high': 5, 'n_cat_low': 2, 'bins': 9}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:00,876] Trial 34 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 4, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:01,160] Trial 37 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:01,310] Trial 31 finished with value: 0.864386187401079 and parameters: {'n_cat_high': 5, 'n_cat_low': 4, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:01,957] Trial 39 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:02,191] Trial 38 finished with value: 0.8744944159562872 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 8}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:02,604] Trial 43 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,252] Trial 44 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,379] Trial 45 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,551] Trial 46 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,568] Trial 47 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,659] Trial 40 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,724] Trial 41 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:03,791] Trial 42 finished with value: 0.8644276021790386 and parameters: {'n_cat_high': 2, 'n_cat_low': 2, 'bins': 6}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:06,559] Trial 48 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "[I 2025-02-10 21:59:06,863] Trial 49 finished with value: 0.8740782373527258 and parameters: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 7}. Best is trial 17 with value: 0.8744944159562872.\n",
      "La mejor configuración es: {'n_cat_high': 2, 'n_cat_low': 3, 'bins': 8} con ROC-AUC = 0.8744944159562872\n",
      "Active run id is: 055d2b0867ad4f838689027d032403f9\n",
      "Active run name is: useful-quail-906\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Función principal: optimización bayesiana y registro en MLflow\n",
    "# -----------------------------\n",
    "def main() -> None:\n",
    "    # Crear las carpetas necesarias\n",
    "    settings.EXPERIMENTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    pipeline_dir: Path = Path(settings.SRC_DIR) / 'pipelines'\n",
    "    pipeline_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    mlflow.set_tracking_uri(settings.MLFLOW_TRACKING_URI)\n",
    "    mlflow.set_experiment('feature_engineering_experiment')\n",
    "    \n",
    "    # Parámetros fijos para XGBoost\n",
    "    global params, num_boost_round, nfold, early_stopping_rounds\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eta': 0.1,\n",
    "        'eval_metric': ['auc', 'logloss'],\n",
    "        'seed': SEED,\n",
    "        'device': 'cuda'  # Usar GPU mediante la API nativa\n",
    "    }\n",
    "    num_boost_round = 300\n",
    "    nfold = 10\n",
    "    early_stopping_rounds = 10\n",
    "    \n",
    "    # Crear el callback de MLflow para Optuna\n",
    "    mlflow_callback = MLflowCallback(\n",
    "        tracking_uri=settings.MLFLOW_TRACKING_URI,\n",
    "        create_experiment=False\n",
    "    )\n",
    "    \n",
    "    # Crear el estudio de Optuna y ejecutar la optimización\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    \n",
    "    # Especificamos, por ejemplo, 50 trials\n",
    "    study.optimize(\n",
    "        func=objective, \n",
    "        n_trials=50, \n",
    "        callbacks=[mlflow_callback],\n",
    "        n_jobs=-1,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    best_trial = study.best_trial\n",
    "    print(f'La mejor configuración es: {best_trial.params} con ROC-AUC = {best_trial.value}')\n",
    "    \n",
    "    # Reconstruir la pipeline con la mejor configuración y ajustarla sobre X_train\n",
    "    best_pipeline = build_pipeline(\n",
    "        best_trial.params['n_cat_high'],\n",
    "        best_trial.params['n_cat_low'],\n",
    "        best_trial.params['bins']\n",
    "    )\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardar la pipeline en un archivo .pkl en settings.MODELS_DIR / artifacts\n",
    "    best_pipeline_file: Path = pipeline_dir / 'pipeline_feature_engineering.pkl'\n",
    "    joblib.dump(best_pipeline, str(best_pipeline_file))\n",
    "    \n",
    "    # Registrar la mejor pipeline y sus métricas en un run final de MLflow\n",
    "    with mlflow.start_run():\n",
    "        current_run = mlflow.active_run()\n",
    "        print(f'Active run id is: {current_run.info.run_id}')\n",
    "        print(f'Active run name is: {current_run.info.run_name}')\n",
    "        mlflow.log_params(best_trial.params)\n",
    "        mlflow.log_metric('best_roc_auc', best_trial.value)\n",
    "        mlflow.log_artifact(str(best_pipeline_file), artifact_path='artifacts')\n",
    "        mlflow.end_run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "# Ruta al archivo de configuración usando pathlib\n",
    "config_file_path = Path(settings.CONFIG_DIR) / 'config.toml'\n",
    "\n",
    "# Cargar el archivo de configuración existente, o inicializar un diccionario vacío si no existe\n",
    "if config_file_path.exists():\n",
    "    with config_file_path.open('r') as file:\n",
    "        config = toml.load(file)\n",
    "else:\n",
    "    config = {}\n",
    "    \n",
    "# Actualizamos (o agregamos) la sección 'pipeline-feature-selection'\n",
    "config['xgb-params'] = params\n",
    "\n",
    "# Escribimos los cambios en el archivo de configuración\n",
    "with config_file_path.open('w') as file:\n",
    "    toml.dump(config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 21:59:28 -0500] [230788] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-02-10 21:59:28 -0500] [230788] [INFO] Listening at: http://127.0.0.1:5000 (230788)\n",
      "[2025-02-10 21:59:28 -0500] [230788] [INFO] Using worker: sync\n",
      "[2025-02-10 21:59:28 -0500] [230789] [INFO] Booting worker with pid: 230789\n",
      "[2025-02-10 21:59:28 -0500] [230790] [INFO] Booting worker with pid: 230790\n",
      "[2025-02-10 21:59:28 -0500] [230791] [INFO] Booting worker with pid: 230791\n",
      "[2025-02-10 21:59:28 -0500] [230792] [INFO] Booting worker with pid: 230792\n",
      "[2025-02-10 22:00:12 -0500] [230788] [INFO] Handling signal: int\n",
      "^C\n",
      "\n",
      "Aborted!\n",
      "[2025-02-10 22:00:13 -0500] [230790] [INFO] Worker exiting (pid: 230790)\n",
      "[2025-02-10 22:00:13 -0500] [230789] [INFO] Worker exiting (pid: 230789)\n",
      "[2025-02-10 22:00:13 -0500] [230791] [INFO] Worker exiting (pid: 230791)\n",
      "[2025-02-10 22:00:13 -0500] [230792] [INFO] Worker exiting (pid: 230792)\n",
      "[2025-02-10 22:00:13 -0500] [230788] [ERROR] Worker (pid:230791) was sent SIGHUP!\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --backend-store-uri \"{settings.MLFLOW_TRACKING_URI}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-meli-u7R8qZeO-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
